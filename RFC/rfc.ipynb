{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477ff41",
   "metadata": {},
   "source": [
    "# Random Forrest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7670f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (\n",
    "    ParameterSampler,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from Transformer import ReplaceZeroWithMean\n",
    "\n",
    "DATAPATH = \"../Data\"\n",
    "MODELPATH = \"../Data/Models/RFC\"\n",
    "\n",
    "data = pd.read_csv(f\"{DATAPATH}/diabetes.csv\")\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=1)\n",
    "imputer = ReplaceZeroWithMean([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"BMI\"])\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a5be2",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84abd31",
   "metadata": {},
   "source": [
    "## WITHOUT Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_base = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
    "rfc_base.fit(X_train, y_train)\n",
    "print(rfc_base.score(X_test, y_test))\n",
    "\n",
    "joblib.dump(rfc_base, f\"{MODELPATH}/RFC_no_hyper.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af82b6",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75925151",
   "metadata": {},
   "source": [
    "## WITH Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.logspace(-2, 2, 50),\n",
    "# np.linspace(50, 1000, 10),\n",
    "from pprint import pprint\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "param_dist = {  # TODO: 0.857\n",
    "    \"n_estimators\": list(range(50, 150, 10)),\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": np.linspace(2, 50, 2, dtype=np.int8),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_leaf_nodes\": [None, 5, 8, 9, 10, 11, 12, 13, 14, 15, 20, 50, 100],\n",
    "    \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "# param_dist = {  # TODO: 0.837\n",
    "#     \"n_estimators\": list(range(50, 500, 50)),  # Number of trees in the forest\n",
    "#     \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],  # Splitting criteria\n",
    "#     \"max_depth\": [None] + list(range(10, 110, 10)),  # Maximum depth of the trees\n",
    "#     \"min_samples_split\": list(range(2, 21, 2)),  # Minimum samples required to split a node\n",
    "#     \"min_samples_leaf\": list(range(1, 21, 2)),  # Minimum samples required to form a leaf\n",
    "#     \"min_weight_fraction_leaf\": np.linspace(0.0, 0.5, 6),  # Minimum weighted fraction of the sum of weights at a leaf\n",
    "#     \"max_features\": [\"sqrt\", \"log2\", None, 0.5, 0.75],  # Number of features to consider for the best split\n",
    "#     \"max_leaf_nodes\": [None] + list(range(10, 200, 20)),  # Maximum number of leaf nodes\n",
    "#     \"bootstrap\": [True],  # Whether to use bootstrap samples\n",
    "#     \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],  # Weights associated with classes\n",
    "#     \"ccp_alpha\": np.linspace(0.0, 0.1, 5),  # Complexity parameter for pruning\n",
    "#     \"max_samples\": [None] + list(np.linspace(0.5, 1.0, 6)),  # Fraction of samples to draw when bootstrap is True\n",
    "# }\n",
    "\n",
    "param_sampler = list(ParameterSampler(param_dist, n_iter=10000, random_state=1))\n",
    "\n",
    "\n",
    "def train_and_evaluate(params):\n",
    "    model = RandomForestClassifier(n_jobs=-1, random_state=1, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    return test_score, model\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(train_and_evaluate)(params) for params in param_sampler)\n",
    "\n",
    "rfc_hpt_score, rfc_hpt = max(results, key=lambda x: x[0])\n",
    "print(rfc_hpt_score)\n",
    "\n",
    "joblib.dump(rfc_hpt, f\"{MODELPATH}/RFC_hyper.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb057302",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d23f2e",
   "metadata": {},
   "source": [
    "## WITH Hyperparamerter Tuning AND Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f157f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {  # 0.831\n",
    "    \"n_estimators\": list(range(50, 150, 15)),\n",
    "    \"criterion\": [\"gini\", \"log_loss\"],\n",
    "    \"max_depth\": np.linspace(2, 50, 3, dtype=np.int8),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_leaf_nodes\": [None, 5, 8, 9, 10, 11, 12, 20, 50, 100],\n",
    "    \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
    "models = RandomizedSearchCV(rfc, param_distributions=param_dist, n_iter=5000, cv=6, n_jobs=-1)\n",
    "models.fit(X_train, y_train)\n",
    "\n",
    "rfc_hpt_cv = models.best_estimator_\n",
    "print(rfc_hpt_cv.score(X_test, y_test))\n",
    "\n",
    "joblib.dump(rfc_hpt_cv, f\"{MODELPATH}/RFC_hyper_cv.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebe0c7",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4e59c",
   "metadata": {},
   "source": [
    "## WITH Hyperparamerter Tuning AND Cross Validation (Stratisfied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "param_dist = {  # 0.831\n",
    "    \"n_estimators\": list(range(50, 150, 15)),\n",
    "    \"criterion\": [\"gini\", \"log_loss\"],\n",
    "    \"max_depth\": np.linspace(2, 50, 3, dtype=np.int8),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_leaf_nodes\": [None, 5, 8, 9, 10, 11, 12, 20, 50, 100],\n",
    "    \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
    "cv_split = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "models = RandomizedSearchCV(rfc, param_distributions=param_dist, n_iter=5000, cv=cv_split, n_jobs=-1)\n",
    "models.fit(X_train, y_train)\n",
    "\n",
    "rfc_hpt_cv = models.best_estimator_\n",
    "print(rfc_hpt_cv.score(X_test, y_test))\n",
    "\n",
    "joblib.dump(rfc_hpt_cv, f\"{MODELPATH}/RFC_hyper_cv.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edbcb4",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eadda",
   "metadata": {},
   "source": [
    "## Further Parameter Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09520c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_features=\"log2\", class_weight=\"balanced\", n_jobs=-1, random_state=1)\n",
    "param_grid = {\n",
    "    \"n_estimators\": 125,\n",
    "    \"max_leaf_nodes\": 20,\n",
    "    \"max_depth\": 26,\n",
    "}\n",
    "for param, value in param_grid.items():\n",
    "    percent = 5\n",
    "    param_grid.update(\n",
    "        {\n",
    "            param: [int(value * i / 100) for i in range(105, 130, percent)]\n",
    "            + [value]\n",
    "            + [int(value * i / 100) for i in range(95, 70, -percent)]\n",
    "        }\n",
    "    )\n",
    "pprint(param_grid)  # TODO: 0.837\n",
    "\n",
    "models = GridSearchCV(rfc, param_grid, cv=10, n_jobs=-1)\n",
    "models.fit(X_train, y_train)\n",
    "\n",
    "rfc_best = models.best_estimator_\n",
    "print(rfc_best.score(X_test, y_test))\n",
    "\n",
    "joblib.dump(rfc_best, f\"{MODELPATH}/RFC_hyper_cv_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef323894",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb14b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RFC': {'F1-Score': 0.7222222222222222,\n",
      "         'Precision': np.float64(0.6256799803969615),\n",
      "         'Score': 0.8051948051948052},\n",
      " 'RFC_hyper': {'F1-Score': 0.8166666666666667,\n",
      "               'Precision': np.float64(0.7105694305694306),\n",
      "               'Score': 0.8571428571428571},\n",
      " 'RFC_hyper_cv': {'F1-Score': 0.6915887850467289,\n",
      "                  'Precision': np.float64(0.5955544455544456),\n",
      "                  'Score': 0.7857142857142857},\n",
      " 'RFC_hyper_cv_tuned': {'F1-Score': 0.7899159663865546,\n",
      "                        'Precision': np.float64(0.6795048701298702),\n",
      "                        'Score': 0.8376623376623377}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "\n",
    "RFC_URL = \"../Data/Models/RFC\"\n",
    "SVM_URL = \"../Data/Models/SVM\"\n",
    "\n",
    "models = {\n",
    "    \"RFC\": f\"{RFC_URL}/RFC_no_hyper.pkl\",\n",
    "    \"RFC_hyper\": f\"{RFC_URL}/RFC_hyper.pkl\",\n",
    "    \"RFC_hyper_cv\": f\"{RFC_URL}/RFC_hyper_cv.pkl\",\n",
    "    \"RFC_hyper_cv_tuned\": f\"{RFC_URL}/RFC_hyper_cv_tuned.pkl\",\n",
    "    # \"SVM\": f\"{SVM_URL}/SVM_no_hyper.pkl\",\n",
    "    # \"SVM_para_grid\": f\"{SVM_URL}/SVM_para_grid.pkl\",\n",
    "    # \"SVM_para_sampl\": f\"{SVM_URL}/SVM_para_sample.pkl\",\n",
    "}\n",
    "\n",
    "model_scores = {}\n",
    "for name, model in models.items():\n",
    "    model = joblib.load(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    model_scores.update(\n",
    "        {\n",
    "            name: {\n",
    "                \"Score\": model.score(X_test, y_test),\n",
    "                \"F1-Score\": f1_score(y_test, model.predict(X_test)),\n",
    "                \"Precision\": average_precision_score(y_test, model.predict(X_test)),\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "pprint(model_scores)\n",
    "\n",
    "for model_name, scores in model_scores.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for score_name, score in scores:\n",
    "        print(f\"{score_name: 20}:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
