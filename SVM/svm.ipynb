{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477ff41",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "### with Hyperparameter Tuning\n",
    "\n",
    "### Hinweis:\n",
    "Anders als in den Praktika und Vorlesungen verwenden wir hier nicht `Scikit-learn`, sondern die Bibliothek `cuML` (CUDA Machine Learning). Diese ermöglicht es uns, unsere SVMs auf einer NVIDIA GPU zu trainieren, was den Trainingsprozess extrem beschleunigt. An der Herangehensweise und der Art, wie wir die Hyperparameter tunen, ändert sich dadurch jedoch nichts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd90c6d",
   "metadata": {},
   "source": [
    "1. Laden der aufbereiteten Daten der vorherigen Gruppe: (Da wir cuML verwenden, benutzen wir hier ein cuDF DataFrame anstelle eines Pandas DataFrame.)\n",
    "2. cuML akzeptiert nur Arrays und keine DataFrames, deswegen müssen wir noch die Sets und Labels in ein CuPy-Array umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7670f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "from cuml.svm import SVC\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "from cuml.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "DATAPATH = '../Data/'\n",
    "MODELPATH = '../Data/Models/SVM/'\n",
    "MODELPATHSKLEARN = '../Data/Models/SVM/SVM_sklearn/'\n",
    "\n",
    "train_set = cudf.read_csv(DATAPATH + 'train_set.csv')\n",
    "train_labels = cudf.read_csv(DATAPATH + 'train_labels.csv')\n",
    "test_set = cudf.read_csv(DATAPATH + 'test_set.csv')\n",
    "test_labels = cudf.read_csv(DATAPATH + 'test_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec5bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467246055603\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "test_pred = clf.predict(test_set)\n",
    "accuracy_score = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "joblib.dump(clf, MODELPATH + 'SVM_no_hyper.pkl')\n",
    "\n",
    "print(f'Accuracy: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590745c",
   "metadata": {},
   "source": [
    "* Ohne Hyperparameter Tuning erhalten wir eine Accuracy von **ca. 0.753** ein wert den wir auf jeden fall noch verbessern wollen.\n",
    "* Als erstes verwenden wir `ParameterSampler`, um eine breitere Fläche an Hyperparametern testen zu koennen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1977591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_sampl.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'degree': [2, 3, 4, 5, 6], # Macht natrülich nur Sinn, wenn degree > 1 da sonst linear\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'coef0': np.linspace(-1, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    }\n",
    "]\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_sampled_params = []\n",
    "for params in param_distributions:\n",
    "    sampler = ParameterSampler(params, n_iter=n_iter, random_state=42)\n",
    "    sampled_params = list(sampler)\n",
    "    all_sampled_params.extend(sampled_params)\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "for params in all_sampled_params:\n",
    "    try:\n",
    "        clf.set_params(**params)\n",
    "        clf.fit(train_set, train_labels)\n",
    "        predictions = clf.predict(test_set)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping invalid parameter combination: {params}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels) \n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_sampl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9b964d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(0.1), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "Best accuracy: 0.7662337422370911\n",
      "Time taken: 35.68 seconds\n",
      "Test accuracy with best model: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Test accuracy with best model: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eadda",
   "metadata": {},
   "source": [
    "### 5. Parameter-Optimierung mit `ParameterSampler`\n",
    "\n",
    "Mithilfe des `ParameterSamplers` konnten wir einige vielversprechende Parameter identifizieren:\n",
    "\n",
    "- Gefundene Parameter:\n",
    "    -  kernel: poly\n",
    "    -  C: 1.0\n",
    "    -  degree: 5\n",
    "    -  tol: 0.1\n",
    "    -  gamma: 0.1\n",
    "    -  max_iter: 4000\n",
    "    -  class_weight: balanced\n",
    "\n",
    "- Modell-Performance:\n",
    "    - Validierungsgenauigkeit: 76.62%\n",
    "    - Testgenauigkeit: 70.13% (Hinweis auf Overfitting)\n",
    "\n",
    "- Trainingszeit: 21.55 Sekunden\n",
    "\n",
    "### 6. Verfeinerung der Hyperparameter mit `ParameterGrid`\n",
    "\n",
    "Im nächsten Schritt werden wir nun ein `ParameterGrid` verwenden, um die Hyperparameter weiter zu optimieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09520c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_grid.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.01, 0.1, 0.8, 0.9, 1, 1.1, 1.2, 2, 5, 10], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(train_set, train_labels)\n",
    "    predictions = clf.predict(test_set)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params    \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels)\n",
    "test_predictions = best_model.predict(test_set)\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8831b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GRID SEARCH RESULTS\n",
      "==================================================\n",
      "\n",
      "Best Parameters Found:\n",
      "  C: 1.2\n",
      "  class_weight: balanced\n",
      "  degree: 4\n",
      "  gamma: 0.07\n",
      "  kernel: poly\n",
      "  max_iter: 3900.0\n",
      "  tol: 0.1\n",
      "\n",
      "Model Performance:\n",
      "  Validation Accuracy: 78.57%\n",
      "  Test Accuracy: 66.88%\n",
      "\n",
      "Training Time: 436.49 seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Validation Accuracy: {best_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"\\nTraining Time: {end_time - start_time:.2f} seconds\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bbc59",
   "metadata": {},
   "source": [
    "Obwohl wir scheinbar bessere Parameter gefunden haben, hat sich die Test-Genauigkeit sogar verschlechtert! Ein klares Zeichen für Overfitting.\n",
    "\n",
    "- Best Parameters Found:\n",
    "  - C: 1.2\n",
    "  - class_weight: balanced\n",
    "  - degree: 4\n",
    "  - gamma: 0.07\n",
    "  - kernel: poly\n",
    "  - max_iter: 3900.0\n",
    "  - tol: 0.1\n",
    "\n",
    "- Model Performance:\n",
    "  - **Validation Accuracy: 78.57%**\n",
    "  - **Test Accuracy: 66.88%**\n",
    "\n",
    "- Training Time: 406.26 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b5275",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Bisher haben wir verschiedene Methoden des Hyperparameter-Tunings betrachtet, um unsere Modelle zu verbessern. Um das volle Potenzial des Tunings auszuschöpfen und vor allem Overfitting zu vermeiden, benötigen wir jedoch ein weiteres wichtiges Werkzeug: die Cross-Validation (Kreuzvalidierung).\n",
    "\n",
    "Im nächsten Schritt werden wir wieder damit beginnen, die Parameter zufällig zu wählen. Dieses Mal werden wir jedoch zusätzlich die Cross-Validation verwenden.\n",
    "\n",
    "wir benutzen wieder die selbe Parameter Distrobution wie bei `ParameterSampler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8968c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'degree': [2, 3, 4, 5, 6], # Macht natrülich nur Sinn, wenn degree > 1 da sonst linear\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'coef0': np.linspace(-1, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5080b404",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m svm_rnd_cv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(SVC(), param_distributions, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msvm_rnd_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:932\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    928\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 932\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    935\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2716\u001b[0m, in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2711\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cv\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cv, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m   2713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2714\u001b[0m         classifier\n\u001b[1;32m   2715\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2716\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   2717\u001b[0m     ):\n\u001b[1;32m   2718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m StratifiedKFold(cv)\n\u001b[1;32m   2719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:333\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:172\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/_array_api.py:832\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    830\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 832\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/utils/performance_tracking.py:51\u001b[0m, in \u001b[0;36m_performance_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nvtx\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m     44\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m     45\u001b[0m         nvtx\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[1;32m     46\u001b[0m             message\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/core/frame.py:440\u001b[0m, in \u001b[0;36mFrame.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;129m@_performance_tracking\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplicit conversion to a host NumPy array via __array__ is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed, To explicitly construct a GPU matrix, consider using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.to_cupy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo explicitly construct a host matrix, consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing .to_numpy().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy()."
     ]
    }
   ],
   "source": [
    "svm_rnd_cv = RandomizedSearchCV(SVC(), param_distributions, n_iter=50, random_state=42, cv=5)\n",
    "svm_rnd_cv.fit(train_set, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
