{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477ff41",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "### with Hyperparameter Tuning\n",
    "\n",
    "### Hinweis:\n",
    "Anders als in den Praktika und Vorlesungen verwenden wir hier nicht `Scikit-learn`, sondern die Bibliothek `cuML` (CUDA Machine Learning). Diese ermöglicht es SVMs auf der GPU zu trainieren, was den Trainingsprozess extrem beschleunigt. An der Herangehensweise und der Art, wie wir die Hyperparameter tunen, ändert sich dadurch nichts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7670f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "from cuml.svm import SVC\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "from cuml.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "DATAPATH = '../Data/'\n",
    "MODELPATH = '../Data/Models/SVM/'\n",
    "MODELPATHSKLEARN = '../Data/Models/SVM/SVM_sklearn/'\n",
    "\n",
    "train_set = cudf.read_csv(DATAPATH + 'train_set.csv')\n",
    "train_labels = cudf.read_csv(DATAPATH + 'train_labels.csv')\n",
    "test_set = cudf.read_csv(DATAPATH + 'test_set.csv')\n",
    "test_labels = cudf.read_csv(DATAPATH + 'test_labels.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca5981",
   "metadata": {},
   "source": [
    "# WITHOUT Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec5bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467246055603\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "test_pred = clf.predict(test_set)\n",
    "accuracy_score = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "joblib.dump(clf, MODELPATH + 'SVM_no_hyper.pkl')\n",
    "\n",
    "print(f'Accuracy: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590745c",
   "metadata": {},
   "source": [
    "# With (Random) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a945556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'degree': [2, 3, 4, 5, 6], # Macht natrülich nur Sinn, wenn degree > 1 da sonst linear\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'coef0': np.linspace(-1, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1977591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_sampl.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 100\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_sampled_params = []\n",
    "for params in param_distributions:\n",
    "    sampler = ParameterSampler(params, n_iter=n_iter, random_state=42)\n",
    "    sampled_params = list(sampler)\n",
    "    all_sampled_params.extend(sampled_params)\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for params in all_sampled_params:\n",
    "    try:\n",
    "        clf.set_params(**params)\n",
    "        clf.fit(train_set, train_labels)\n",
    "        predictions = clf.predict(test_set)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        counter += 1\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping invalid parameter combination: {params}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels) \n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_sampl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b964d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(0.1), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "Best accuracy: 0.7662337422370911\n",
      "Time taken: 36.10 seconds\n",
      "Test accuracy with best model: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Test accuracy with best model: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eadda",
   "metadata": {},
   "source": [
    "# Further Hyperparameter Tuning with Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09520c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_grid.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.01, 0.1, 0.8, 0.9, 1, 1.1, 1.2, 2, 5, 10], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(train_set, train_labels)\n",
    "    predictions = clf.predict(test_set)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params    \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels)\n",
    "test_predictions = best_model.predict(test_set)\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8831b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GRID SEARCH RESULTS\n",
      "==================================================\n",
      "\n",
      "Best Parameters Found:\n",
      "  C: 1.2\n",
      "  class_weight: balanced\n",
      "  degree: 4\n",
      "  gamma: 0.07\n",
      "  kernel: poly\n",
      "  max_iter: 3900.0\n",
      "  tol: 0.1\n",
      "\n",
      "Model Performance:\n",
      "  Validation Accuracy: 78.57%\n",
      "  Test Accuracy: 66.88%\n",
      "\n",
      "Training Time: 442.50 seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Validation Accuracy: {best_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"\\nTraining Time: {end_time - start_time:.2f} seconds\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bbc59",
   "metadata": {},
   "source": [
    "# (Random) Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f26ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml\n",
    "from cuml.svm import SVC\n",
    "from cuml.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterSampler, KFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "class CuMLRandomizedSearchCV:\n",
    "\n",
    "    model = SVC()\n",
    "\n",
    "    def __init__(self, param_distributions, n_iter=10, cv_method='kfold', k=5, random_state=42):\n",
    "        self.param_distributions = param_distributions\n",
    "        self.n_iter = n_iter\n",
    "        self.cv_method = cv_method\n",
    "        self.k = k\n",
    "        self.random_state = random_state\n",
    "        self.results = []\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def _sample_parameters(self):\n",
    "        \"\"\"Sample parameter combinations from the given distributions.\"\"\"\n",
    "        for param_distribution in self.param_distributions:\n",
    "            sampler = ParameterSampler(param_distribution, n_iter=self.n_iter, random_state=self.random_state)\n",
    "            for sampled_params in sampler:\n",
    "                yield sampled_params\n",
    "\n",
    "    def _train_and_evaluate(self, X, y, sampled_params):\n",
    "        \"\"\"Train and evaluate a model with given parameters using the chosen CV method.\"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        if self.cv_method == 'kfold':\n",
    "            scores = self._kfold_cv(X, y, sampled_params)\n",
    "        elif self.cv_method == 'stratified':\n",
    "            scores = self._stratified_kfold_cv(X, y, sampled_params)\n",
    "        elif self.cv_method == 'loocv':\n",
    "            scores = self._loocv(X, y, sampled_params)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cv_method. Choose 'kfold', 'stratified', or 'loocv'.\")\n",
    "        \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def _kfold_cv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform k-fold cross-validation.\"\"\"\n",
    "        from sklearn.model_selection import KFold\n",
    "        \n",
    "        kf = KFold(n_splits=self.k, shuffle=True, random_state=self.random_state)\n",
    "        scores = []\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "            print(f\"  Training and evaluating fold {fold+1}/{self.k}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def _stratified_kfold_cv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform stratified k-fold cross-validation.\"\"\"\n",
    "        from cuml.model_selection import StratifiedKFold\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=self.k, random_state=self.random_state, shuffle=True)\n",
    "        scores = []\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "            print(f\"  Training and evaluating fold {fold+1}/{self.k}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def _loocv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform Leave-One-Out cross-validation.\"\"\"\n",
    "        from sklearn.model_selection import LeaveOneOut\n",
    "        \n",
    "        loo = LeaveOneOut()\n",
    "        scores = []\n",
    "        for i, (train_index, val_index) in enumerate(loo.split(X)):\n",
    "            print(f\"  Training and evaluating sample {i+1}/{len(X)}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the randomized search CV to the data.\"\"\"\n",
    "        print(\"Starting Randomized Search CV...\")\n",
    "        for i, sampled_params in enumerate(self._sample_parameters()):\n",
    "            print(f\"Evaluating parameter set {i+1}/{self.n_iter * len(self.param_distributions)}: {sampled_params}\")\n",
    "            avg_score = self._train_and_evaluate(X, y, sampled_params)\n",
    "            print(f\"  Average CV score: {avg_score:.4f}\")\n",
    "            self.results.append({'params': sampled_params, 'score': avg_score})\n",
    "\n",
    "        best_result = max(self.results, key=lambda x: x['score'])\n",
    "        self.best_params = best_result['params']\n",
    "        self.best_score = best_result['score']\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        print(\"Randomized Search CV complete.\")\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        print(f\"Best CV score: {self.best_score:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the best found parameters.\"\"\"\n",
    "        print(\"Training final model with best parameters...\")\n",
    "        final_model = SVC(**self.best_params)\n",
    "        final_model.fit(self.X_train, self.y_train)\n",
    "        print(\"Final model training complete.\")\n",
    "        return final_model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Score the model's performance.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def best_params(self):\n",
    "        \"\"\"Return the best parameters found by the randomized search.\"\"\"\n",
    "        return self.best_params\n",
    "    \n",
    "    def best_score(self):\n",
    "        \"\"\"Return the best score found by the randomized search.\"\"\"\n",
    "        return self.best_score\n",
    "    \n",
    "    def results(self):\n",
    "        \"\"\"Return the results of the randomized search.\"\"\"\n",
    "        return self.results\n",
    "    \n",
    "    def save_best_model(self):\n",
    "        \"\"\"Save the best model to a file.\"\"\"\n",
    "        final_model = SVC(**self.best_params)\n",
    "        final_model.fit(self.X_train, self.y_train)\n",
    "        joblib.dump(final_model, DATAPATH + 'SVM_rnd_search_CV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3116940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomized Search CV...\n",
      "Evaluating parameter set 1/80: {'tol': np.float64(0.0001), 'max_iter': 4000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 2/80: {'tol': np.float64(0.1), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 3/80: {'tol': np.float64(0.1), 'max_iter': 2000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7812\n",
      "Evaluating parameter set 4/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7987\n",
      "Evaluating parameter set 5/80: {'tol': np.float64(0.0001), 'max_iter': 4000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7850\n",
      "Evaluating parameter set 6/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7850\n",
      "Evaluating parameter set 7/80: {'tol': np.float64(0.001), 'max_iter': 3000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7850\n",
      "Evaluating parameter set 8/80: {'tol': np.float64(0.01), 'max_iter': 3000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7800\n",
      "Evaluating parameter set 9/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 2000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 10/80: {'tol': np.float64(0.0001), 'max_iter': 5000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7512\n",
      "Evaluating parameter set 11/80: {'tol': np.float64(0.0001), 'max_iter': 2000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5800\n",
      "Evaluating parameter set 12/80: {'tol': np.float64(1e-06), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7987\n",
      "Evaluating parameter set 13/80: {'tol': np.float64(0.01), 'max_iter': 2000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7800\n",
      "Evaluating parameter set 14/80: {'tol': np.float64(0.001), 'max_iter': 5000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7825\n",
      "Evaluating parameter set 15/80: {'tol': np.float64(0.01), 'max_iter': 2000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7500\n",
      "Evaluating parameter set 16/80: {'tol': np.float64(0.1), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7812\n",
      "Evaluating parameter set 17/80: {'tol': np.float64(1e-06), 'max_iter': 3000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7850\n",
      "Evaluating parameter set 18/80: {'tol': np.float64(1e-06), 'max_iter': 3000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 19/80: {'tol': np.float64(0.0001), 'max_iter': 5000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5800\n",
      "Evaluating parameter set 20/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 1000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7825\n",
      "Evaluating parameter set 21/80: {'tol': np.float64(0.001), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 6, 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 22/80: {'tol': np.float64(0.1), 'max_iter': 3000, 'kernel': 'poly', 'gamma': np.float64(1.0), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 23/80: {'tol': np.float64(1e-07), 'max_iter': 1000, 'kernel': 'poly', 'gamma': np.float64(0.001), 'degree': 4, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7375\n",
      "Evaluating parameter set 24/80: {'tol': np.float64(0.001), 'max_iter': 2000, 'kernel': 'poly', 'gamma': np.float64(0.01), 'degree': 3, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7500\n",
      "Evaluating parameter set 25/80: {'tol': np.float64(1e-06), 'max_iter': 5000, 'kernel': 'poly', 'gamma': np.float64(0.1), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7800\n",
      "Evaluating parameter set 26/80: {'tol': np.float64(1e-07), 'max_iter': 1000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 2, 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 27/80: {'tol': np.float64(0.001), 'max_iter': 2000, 'kernel': 'poly', 'gamma': np.float64(1000.0), 'degree': 3, 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 28/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 3000, 'kernel': 'poly', 'gamma': np.float64(0.001), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7312\n",
      "Evaluating parameter set 29/80: {'tol': np.float64(0.1), 'max_iter': 2000, 'kernel': 'poly', 'gamma': np.float64(100.0), 'degree': 4, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 30/80: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(1000.0), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 31/80: {'tol': np.float64(0.01), 'max_iter': 1000, 'kernel': 'poly', 'gamma': np.float64(1000.0), 'degree': 3, 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.4650\n",
      "Evaluating parameter set 32/80: {'tol': np.float64(0.1), 'max_iter': 5000, 'kernel': 'poly', 'gamma': np.float64(0.001), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 33/80: {'tol': np.float64(0.01), 'max_iter': 3000, 'kernel': 'poly', 'gamma': np.float64(0.1), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7787\n",
      "Evaluating parameter set 34/80: {'tol': np.float64(0.001), 'max_iter': 3000, 'kernel': 'poly', 'gamma': np.float64(1000.0), 'degree': 6, 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.4650\n",
      "Evaluating parameter set 35/80: {'tol': np.float64(0.01), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 3, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 36/80: {'tol': np.float64(0.001), 'max_iter': 2000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 2, 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 37/80: {'tol': np.float64(1e-06), 'max_iter': 3000, 'kernel': 'poly', 'gamma': np.float64(0.01), 'degree': 3, 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7725\n",
      "Evaluating parameter set 38/80: {'tol': np.float64(1e-06), 'max_iter': 5000, 'kernel': 'poly', 'gamma': np.float64(100.0), 'degree': 6, 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 39/80: {'tol': np.float64(0.01), 'max_iter': 1000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 40/80: {'tol': np.float64(0.001), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(100.0), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 41/80: {'tol': np.float64(0.001), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(0.001), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 42/80: {'tol': np.float64(0.1), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(0.01), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7850\n",
      "Evaluating parameter set 43/80: {'tol': np.float64(0.1), 'max_iter': 2000, 'kernel': 'rbf', 'gamma': np.float64(10.0), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 44/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(0.001), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7525\n",
      "Evaluating parameter set 45/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 3000, 'kernel': 'rbf', 'gamma': np.float64(0.001), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 46/80: {'tol': np.float64(1e-07), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(0.1), 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7787\n",
      "Evaluating parameter set 47/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 1000, 'kernel': 'rbf', 'gamma': np.float64(0.01), 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7513\n",
      "Evaluating parameter set 48/80: {'tol': np.float64(0.1), 'max_iter': 3000, 'kernel': 'rbf', 'gamma': np.float64(100.0), 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 49/80: {'tol': np.float64(0.01), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(100.0), 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.4650\n",
      "Evaluating parameter set 50/80: {'tol': np.float64(0.01), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(10.0), 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.4900\n",
      "Evaluating parameter set 51/80: {'tol': np.float64(0.001), 'max_iter': 2000, 'kernel': 'rbf', 'gamma': np.float64(0.01), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7500\n",
      "Evaluating parameter set 52/80: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(1.0), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8125\n",
      "Evaluating parameter set 53/80: {'tol': np.float64(0.0001), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(0.1), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7800\n",
      "Evaluating parameter set 54/80: {'tol': np.float64(0.1), 'max_iter': 3000, 'kernel': 'rbf', 'gamma': np.float64(10.0), 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.4900\n",
      "Evaluating parameter set 55/80: {'tol': np.float64(0.001), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(1000.0), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 56/80: {'tol': np.float64(0.001), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(0.1), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7962\n",
      "Evaluating parameter set 57/80: {'tol': np.float64(0.01), 'max_iter': 4000, 'kernel': 'rbf', 'gamma': np.float64(0.001), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7388\n",
      "Evaluating parameter set 58/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 3000, 'kernel': 'rbf', 'gamma': np.float64(0.1), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7513\n",
      "Evaluating parameter set 59/80: {'tol': np.float64(1e-06), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(0.001), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7375\n",
      "Evaluating parameter set 60/80: {'tol': np.float64(0.001), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(100.0), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 61/80: {'tol': np.float64(0.0001), 'max_iter': 2000, 'kernel': 'sigmoid', 'gamma': np.float64(1.0), 'coef0': np.float64(-0.11111111111111116), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8138\n",
      "Evaluating parameter set 62/80: {'tol': np.float64(0.1), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(1.0), 'coef0': np.float64(-0.33333333333333337), 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 63/80: {'tol': np.float64(1e-07), 'max_iter': 1000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(-0.5555555555555556), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 64/80: {'tol': np.float64(1e-06), 'max_iter': 5000, 'kernel': 'sigmoid', 'gamma': np.float64(100.0), 'coef0': np.float64(0.7777777777777777), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 65/80: {'tol': np.float64(1e-07), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(0.33333333333333326), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7375\n",
      "Evaluating parameter set 66/80: {'tol': np.float64(1e-07), 'max_iter': 1000, 'kernel': 'sigmoid', 'gamma': np.float64(10.0), 'coef0': np.float64(0.11111111111111116), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 67/80: {'tol': np.float64(1e-06), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(100.0), 'coef0': np.float64(0.7777777777777777), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 68/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(0.7777777777777777), 'class_weight': 'balanced', 'C': np.float64(0.01)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5150\n",
      "Evaluating parameter set 69/80: {'tol': np.float64(0.0001), 'max_iter': 1000, 'kernel': 'sigmoid', 'gamma': np.float64(1000.0), 'coef0': np.float64(0.7777777777777777), 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 70/80: {'tol': np.float64(9.999999999999999e-06), 'max_iter': 4000, 'kernel': 'sigmoid', 'gamma': np.float64(0.1), 'coef0': np.float64(0.33333333333333326), 'class_weight': 'balanced', 'C': np.float64(10.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7800\n",
      "Evaluating parameter set 71/80: {'tol': np.float64(1e-07), 'max_iter': 5000, 'kernel': 'sigmoid', 'gamma': np.float64(0.1), 'coef0': np.float64(0.11111111111111116), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7962\n",
      "Evaluating parameter set 72/80: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'sigmoid', 'gamma': np.float64(1000.0), 'coef0': np.float64(-0.33333333333333337), 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.8375\n",
      "Evaluating parameter set 73/80: {'tol': np.float64(0.01), 'max_iter': 1000, 'kernel': 'sigmoid', 'gamma': np.float64(1000.0), 'coef0': np.float64(0.33333333333333326), 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 74/80: {'tol': np.float64(0.1), 'max_iter': 5000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(-0.33333333333333337), 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 75/80: {'tol': np.float64(0.001), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(1000.0), 'coef0': np.float64(1.0), 'class_weight': 'balanced', 'C': np.float64(0.001)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 76/80: {'tol': np.float64(0.01), 'max_iter': 4000, 'kernel': 'sigmoid', 'gamma': np.float64(10.0), 'coef0': np.float64(-0.7777777777777778), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 77/80: {'tol': np.float64(0.001), 'max_iter': 2000, 'kernel': 'sigmoid', 'gamma': np.float64(10.0), 'coef0': np.float64(-1.0), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 78/80: {'tol': np.float64(1e-06), 'max_iter': 3000, 'kernel': 'sigmoid', 'gamma': np.float64(0.01), 'coef0': np.float64(0.33333333333333326), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7288\n",
      "Evaluating parameter set 79/80: {'tol': np.float64(0.01), 'max_iter': 4000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(0.33333333333333326), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.5075\n",
      "Evaluating parameter set 80/80: {'tol': np.float64(1e-07), 'max_iter': 4000, 'kernel': 'sigmoid', 'gamma': np.float64(0.1), 'coef0': np.float64(0.11111111111111116), 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating fold 1/5...\n",
      "  Training and evaluating fold 2/5...\n",
      "  Training and evaluating fold 3/5...\n",
      "  Training and evaluating fold 4/5...\n",
      "  Training and evaluating fold 5/5...\n",
      "  Average CV score: 0.7763\n",
      "Randomized Search CV complete.\n",
      "Best parameters found: {'tol': np.float64(0.001), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(10.0), 'degree': 6, 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "Best CV score: 0.8375\n",
      "Training final model with best parameters...\n",
      "Final model training complete.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m searcher \u001b[38;5;241m=\u001b[39m CuMLRandomizedSearchCV(param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkfold\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m searcher\u001b[38;5;241m.\u001b[39mfit(train_set, train_labels)\n\u001b[0;32m----> 3\u001b[0m test_score \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 128\u001b[0m, in \u001b[0;36mCuMLRandomizedSearchCV.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Score the model's performance.\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m     98\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:333\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:172\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/_array_api.py:832\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    830\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 832\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/utils/performance_tracking.py:51\u001b[0m, in \u001b[0;36m_performance_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nvtx\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m     44\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m     45\u001b[0m         nvtx\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[1;32m     46\u001b[0m             message\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/core/frame.py:440\u001b[0m, in \u001b[0;36mFrame.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;129m@_performance_tracking\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplicit conversion to a host NumPy array via __array__ is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed, To explicitly construct a GPU matrix, consider using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.to_cupy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo explicitly construct a host matrix, consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing .to_numpy().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy()."
     ]
    }
   ],
   "source": [
    "searcher = CuMLRandomizedSearchCV(param_distributions=param_distributions, n_iter=20, cv_method='kfold', k=5, random_state=42)\n",
    "searcher.fit(train_set, train_labels)\n",
    "test_score = searcher.score(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0a958ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with best model: 0.5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CuMLRandomizedSearchCV' object has no attribute 'save_best_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy with best model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_best_model\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CuMLRandomizedSearchCV' object has no attribute 'save_best_model'"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy with best model: {test_score}\")\n",
    "\n",
    "searcher.save_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2f34f",
   "metadata": {},
   "source": [
    "# Further Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridCV = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.01, 0.1, 0.8, 0.9, 1, 1.1, 1.2, 2, 5, 10], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12107029",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_search = GridSearchCV(SVC(), param_gridCV, cv=5)\n",
    "svm_grid_search.fit(train_set, train_labels)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param, value in svm_grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Validation Accuracy: {svm_grid_search.best_score_*100:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_model = svm_grid_search.best_estimator_\n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_grid_CV.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
