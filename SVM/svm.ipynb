{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477ff41",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "### with Hyperparameter Tuning\n",
    "\n",
    "### Hinweis:\n",
    "Anders als in den Praktika und Vorlesungen verwenden wir hier nicht `Scikit-learn`, sondern die Bibliothek `cuML` (CUDA Machine Learning). Diese ermöglicht es SVMs auf der GPU zu trainieren, was den Trainingsprozess extrem beschleunigt. An der Herangehensweise und der Art, wie wir die Hyperparameter tunen, ändert sich dadurch nichts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "from IPython.display import HTML\n",
    "from Model_save import save_model_as_sklearn\n",
    "from cuml.svm import SVC\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.model_selection import train_test_split\n",
    "from Transformer_cudf import ReplaceZeroWithMean\n",
    "from cuml.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from cuml.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "DATAPATH = '../Data/'\n",
    "MODELPATH = '../Data/Models/SVM/'\n",
    "\n",
    "\n",
    "data = cudf.read_csv(f\"{DATAPATH}/diabetes.csv\")\n",
    "\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "train_set, temp_set, train_labels, temp_labels = train_test_split(X, y, train_size=0.60, random_state=42)\n",
    "test_set, valid_set, test_labels, valid_labels = train_test_split(temp_set, temp_labels, train_size=0.50, random_state=42)\n",
    "\n",
    "imputer = ReplaceZeroWithMean([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"BMI\"])\n",
    "train_set = imputer.fit_transform(train_set)\n",
    "valid_set = imputer.transform(valid_set)\n",
    "test_set = imputer.transform(test_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_set = scaler.fit_transform(train_set)\n",
    "valid_set = scaler.transform(valid_set)\n",
    "test_set = scaler.transform(test_set)\n",
    "\n",
    "def model_data_print(parameters, score, accuracy, timeStart, timeEnd):\n",
    "\n",
    "    html_output = f\"\"\"\n",
    "    <h3>Best Parameters Found</h3>\n",
    "    <ul>\n",
    "    \"\"\"\n",
    "\n",
    "    for param, value in parameters.items():\n",
    "        html_output += f\"<li>{param}: {value}</li>\"\n",
    "\n",
    "    html_output += f\"\"\"\n",
    "    </ul>\n",
    "    <h3>Model Performance:</h3>\n",
    "    <ul>\n",
    "        <li>Validation Accuracy: <b>{score*100:.2f}%</b></li>\n",
    "        <li>Test Accuracy: <b>{accuracy*100:.2f}%</b></li>\n",
    "    </ul>\n",
    "    <p>Time taken: <b>{timeStart - timeEnd:.2f} .Sec</b></p>\n",
    "    \"\"\"\n",
    "\n",
    "    return HTML(html_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca5981",
   "metadata": {},
   "source": [
    "# WITHOUT Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec5bb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>SVM without hyperparameter tuning</h3>\n",
       "Accuracy: <b>77.27%</b>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "test_pred = clf.predict(test_set)\n",
    "accuracy = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "joblib.dump(clf, MODELPATH + '01_SVM_no_hyper.pkl')\n",
    "save_model_as_sklearn(filename='01_SVM_no_hyper_sklearn.pkl', parameters={})\n",
    "\n",
    "html_output =f\"\"\"\n",
    "<h3>SVM without hyperparameter tuning</h3>\n",
    "Accuracy: <b>{accuracy*100:.2f}%</b>\n",
    "\"\"\"\n",
    "HTML(html_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590745c",
   "metadata": {},
   "source": [
    "# With (Random) Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a945556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'degree': [2, 3, 4, 5, 6], # Macht natrülich nur Sinn, wenn degree > 1 da sonst linear\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'coef0': np.linspace(-1, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1977591",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_sampled_params = []\n",
    "for params in param_distributions:\n",
    "    sampler = ParameterSampler(params, n_iter=n_iter, random_state=42)\n",
    "    sampled_params = list(sampler)\n",
    "    all_sampled_params.extend(sampled_params)\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "\n",
    "for params in all_sampled_params:\n",
    "    try:\n",
    "        clf.set_params(**params)\n",
    "        clf.fit(train_set, train_labels)\n",
    "        predictions = clf.predict(valid_set)\n",
    "        accuracy = accuracy_score(valid_labels, predictions)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping invalid parameter combination: {params}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params, random_state=42)\n",
    "best_model.fit(train_set, train_labels) \n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + '02_SVM_para_sampl.pkl')\n",
    "save_model_as_sklearn(filename='02_SVM_para_sampl_sklearn.pkl', parameters=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b964d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h3>Best Parameters Found</h3>\n",
       "    <ul>\n",
       "    <li>tol: 0.1</li><li>max_iter: 3000</li><li>kernel: poly</li><li>gamma: 0.1</li><li>degree: 6</li><li>class_weight: balanced</li><li>C: 0.1</li>\n",
       "    </ul>\n",
       "    <h3>Model Performance:</h3>\n",
       "    <ul>\n",
       "        <li>Validation Accuracy: <b>77.92%</b></li>\n",
       "        <li>Test Accuracy: <b>72.08%</b></li>\n",
       "    </ul>\n",
       "    <p>Time taken: <b>23.84 .Sec</b></p>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_print(best_params, best_accuracy, test_accuracy, end_time, start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eadda",
   "metadata": {},
   "source": [
    "# Further Hyperparameter Tuning with Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09520c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [19:13:39.641503] SVC with the linear kernel can be much faster using the specialized solver provided by LinearSVC. Consider switching to LinearSVC if tranining takes too long.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'kernel': ['linear'],\n",
    "        'C': [0.8, 0.9, 1, 1.1, 1.2, 2], \n",
    "        'tol': [0.001, 0.01, 0.1],\n",
    "        'gamma': [0.08, 0.09, 0.1, 0.2, 0.3],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(2000, 3000, 10),\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(train_set, train_labels)\n",
    "    predictions = clf.predict(valid_set)\n",
    "    accuracy = accuracy_score(valid_labels, predictions)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params    \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params, random_state=42)\n",
    "best_model.fit(train_set, train_labels)\n",
    "test_predictions = best_model.predict(test_set)\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + '03_SVM_para_grid.pkl')\n",
    "save_model_as_sklearn(filename='03_SVM_para_grid_sklearn.pkl', parameters=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8831b481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h3>Best Parameters Found</h3>\n",
       "    <ul>\n",
       "    <li>C: 1.1</li><li>class_weight: balanced</li><li>degree: 4</li><li>gamma: 0.3</li><li>kernel: linear</li><li>max_iter: 2000</li><li>tol: 0.1</li>\n",
       "    </ul>\n",
       "    <h3>Model Performance:</h3>\n",
       "    <ul>\n",
       "        <li>Validation Accuracy: <b>77.27%</b></li>\n",
       "        <li>Test Accuracy: <b>73.38%</b></li>\n",
       "    </ul>\n",
       "    <p>Time taken: <b>113.67 .Sec</b></p>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_print(best_params, best_accuracy, test_accuracy, end_time, start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bbc59",
   "metadata": {},
   "source": [
    "# (Random) Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e659ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cudf.read_csv(f\"{DATAPATH}/diabetes.csv\")\n",
    "\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "imputer = ReplaceZeroWithMean([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"BMI\"])\n",
    "train_set = imputer.fit_transform(train_set)\n",
    "test_set = imputer.transform(test_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_set = scaler.fit_transform(train_set)\n",
    "test_set = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f26ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuMLRandomizedSearchCV:\n",
    "\n",
    "    def __init__(self, model, param_distributions, n_iter=10, cv=None, random_state=42, verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize the RandomizedSearchCV.\n",
    "\n",
    "        Args:\n",
    "            model (object): The machine learning model to tune. Must have `fit` and `score` methods.\n",
    "            param_distributions (dict): Dictionary of parameter distributions to sample from.\n",
    "            n_iter (int): Number of parameter settings that are sampled.\n",
    "            cv (object): Cross-validation splitting strategy.\n",
    "                         Should be one of KFold, StratifiedKFold, or LeaveOneOut.\n",
    "                         If None, defaults to 5-fold KFold.\n",
    "            random_state (int): Random state for reproducibility.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.param_distributions = param_distributions\n",
    "        self.n_iter = n_iter\n",
    "        self.cv = cv if cv is not None else KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.results = []\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def _sample_parameters(self):\n",
    "        \"\"\"Sample parameter combinations from the given distributions.\"\"\"\n",
    "        for param_distribution in self.param_distributions:\n",
    "            sampler = ParameterSampler(param_distribution, n_iter=self.n_iter, random_state=self.random_state)\n",
    "            for sampled_params in sampler:\n",
    "                yield sampled_params\n",
    "\n",
    "    def _train_and_evaluate(self, X, y, sampled_params):\n",
    "        \"\"\"Train and evaluate a model with given parameters using the chosen CV method.\"\"\"\n",
    "        scores = []\n",
    "        if isinstance(self.cv, LeaveOneOut):\n",
    "            for i, (train_index, val_index) in enumerate(self.cv.split(X, y)):\n",
    "                if self.verbose:\n",
    "                    print(f\" Training and evaluating sample {i+1}/{len(X)}...\")\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "                self.model.set_params(**sampled_params)\n",
    "                self.model.fit(X_train, y_train)\n",
    "                score = self.model.score(X_val, y_val)\n",
    "                scores.append(score)\n",
    "        else:\n",
    "            for fold, (train_index, val_index) in enumerate(self.cv.split(X, y)):\n",
    "                if self.verbose:\n",
    "                    print(f\" Training and evaluating fold {fold+1}/{self.cv.get_n_splits()}...\")\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "                self.model.set_params(**sampled_params)\n",
    "                self.model.fit(X_train, y_train)\n",
    "                score = self.model.score(X_val, y_val)\n",
    "                scores.append(score)\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the randomized search CV to the data.\"\"\"\n",
    "        print(\"Starting Randomized Search CV...\")\n",
    "        for i, sampled_params in enumerate(self._sample_parameters()):\n",
    "            if self.verbose:\n",
    "                print(f\"Evaluating parameter set {i+1}/{self.n_iter * len(self.param_distributions)}: {sampled_params}\")\n",
    "            else:\n",
    "                print(f\"Evaluating parameter set {i+1}/{self.n_iter * len(self.param_distributions)}\")\n",
    "            avg_score = self._train_and_evaluate(X, y, sampled_params)\n",
    "            print(f\"  Average CV score: {avg_score:.4f}\")\n",
    "            self.results.append({'params': sampled_params, 'score': avg_score})\n",
    "\n",
    "        best_result = max(self.results, key=lambda x: x['score'])\n",
    "        self.best_params = best_result['params']\n",
    "        self.best_score = best_result['score']\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        print(\"Randomized Search CV complete.\")\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        print(f\"Best CV score: {self.best_score:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Score the model's performance.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def get_best_params(self):\n",
    "        \"\"\"Return the best parameters found by the randomized search.\"\"\"\n",
    "        return self.best_params\n",
    "\n",
    "    def get_best_score(self):\n",
    "        \"\"\"Return the best score found by the randomized search.\"\"\"\n",
    "        return self.best_score\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Return the results of the randomized search.\"\"\"\n",
    "        return self.results\n",
    "\n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best model found by the randomized search.\"\"\"\n",
    "        return self.model.set_params(**self.best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0472a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 20\n",
    "N_SPLITS = 5\n",
    "RND_STATE = 42\n",
    "\n",
    "svc_rnd_cv = SVC()\n",
    "\n",
    "fold_strategy_kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RND_STATE)\n",
    "fold_strategy_strat = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RND_STATE)\n",
    "fold_strategy_loocv = LeaveOneOut()\n",
    "\n",
    "searcher_kfold = CuMLRandomizedSearchCV(\n",
    "    model=svc_rnd_cv, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=N_ITER, \n",
    "    cv=fold_strategy_kfold, \n",
    "    random_state=RND_STATE,\n",
    "    )\n",
    "\n",
    "searcher_strat = CuMLRandomizedSearchCV(\n",
    "    model=svc_rnd_cv,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=fold_strategy_strat,\n",
    "    random_state=RND_STATE,\n",
    "    )\n",
    "\n",
    "searcher_loocv = CuMLRandomizedSearchCV(\n",
    "    model=svc_rnd_cv,\n",
    "    param_distributions=param_distributions,\n",
    "    cv=fold_strategy_loocv,\n",
    "    random_state=RND_STATE,\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1639a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3116940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomized Search CV...\n",
      "Evaluating parameter set 1/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 2/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 3/80\n",
      "  Average CV score: 0.7329\n",
      "Evaluating parameter set 4/80\n",
      "  Average CV score: 0.6727\n",
      "Evaluating parameter set 5/80\n",
      "  Average CV score: 0.6662\n",
      "Evaluating parameter set 6/80\n",
      "  Average CV score: 0.6662\n",
      "Evaluating parameter set 7/80\n",
      "  Average CV score: 0.6662\n",
      "Evaluating parameter set 8/80\n",
      "  Average CV score: 0.7606\n",
      "Evaluating parameter set 9/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 10/80\n",
      "  Average CV score: 0.7134\n",
      "Evaluating parameter set 11/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 12/80\n",
      "  Average CV score: 0.6727\n",
      "Evaluating parameter set 13/80\n",
      "  Average CV score: 0.7606\n",
      "Evaluating parameter set 14/80\n",
      "  Average CV score: 0.7280\n",
      "Evaluating parameter set 15/80\n",
      "  Average CV score: 0.7134\n",
      "Evaluating parameter set 16/80\n",
      "  Average CV score: 0.7329\n",
      "Evaluating parameter set 17/80\n",
      "  Average CV score: 0.6662\n",
      "Evaluating parameter set 18/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 19/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 20/80\n",
      "  Average CV score: 0.7280\n",
      "Evaluating parameter set 21/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 22/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 23/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 24/80\n",
      "  Average CV score: 0.7492\n",
      "Evaluating parameter set 25/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 26/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 27/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 28/80\n",
      "  Average CV score: 0.7264\n",
      "Evaluating parameter set 29/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 30/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 31/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 32/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 33/80\n",
      "  Average CV score: 0.6890\n",
      "Evaluating parameter set 34/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 35/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 36/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 37/80\n",
      "  Average CV score: 0.7558\n",
      "Evaluating parameter set 38/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 39/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 40/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 41/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 42/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 43/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 44/80\n",
      "  Average CV score: 0.7443\n",
      "Evaluating parameter set 45/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 46/80\n",
      "  Average CV score: 0.6890\n",
      "Evaluating parameter set 47/80\n",
      "  Average CV score: 0.7361\n",
      "Evaluating parameter set 48/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 49/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 50/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 51/80\n",
      "  Average CV score: 0.7492\n",
      "Evaluating parameter set 52/80\n",
      "  Average CV score: 0.6808\n",
      "Evaluating parameter set 53/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 54/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 55/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 56/80\n",
      "  Average CV score: 0.6629\n",
      "Evaluating parameter set 57/80\n",
      "  Average CV score: 0.7410\n",
      "Evaluating parameter set 58/80\n",
      "  Average CV score: 0.7248\n",
      "Evaluating parameter set 59/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 60/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 61/80\n",
      "  Average CV score: 0.6824\n",
      "Evaluating parameter set 62/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 63/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 64/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 65/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 66/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 67/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 68/80\n",
      "  Average CV score: 0.5538\n",
      "Evaluating parameter set 69/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 70/80\n",
      "  Average CV score: 0.7427\n",
      "Evaluating parameter set 71/80\n",
      "  Average CV score: 0.6629\n",
      "Evaluating parameter set 72/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 73/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 74/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 75/80\n",
      "  Average CV score: 0.4936\n",
      "Evaluating parameter set 76/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 77/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 78/80\n",
      "  Average CV score: 0.7231\n",
      "Evaluating parameter set 79/80\n",
      "  Average CV score: 0.4595\n",
      "Evaluating parameter set 80/80\n",
      "  Average CV score: 0.7590\n",
      "Randomized Search CV complete.\n",
      "Best parameters found: {'tol': np.float64(0.01), 'max_iter': 3000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "Best CV score: 0.7606\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'tol' parameter of SVC must be a float in the range (0.0, inf). Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m kfold_test_accuracy_rnd_cv \u001b[38;5;241m=\u001b[39m accuracy_score(test_labels, kfold_test_predictions_rnd_cv)\n\u001b[1;32m     13\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(kfold_best_model_rnd_cv, MODELPATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04_SVM_kfold_rnd_cv.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43msave_model_as_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m04_SVM_kfold_rnd_cv_sklearn.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold_best_params_rnd_cv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/haw/DiabetesPrediction/SVM/Model_save.py:36\u001b[0m, in \u001b[0;36msave_model_as_sklearn\u001b[0;34m(filename, parameters)\u001b[0m\n\u001b[1;32m     34\u001b[0m         parameters[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(value)\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(model, MODELPATHSKLEARN \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'tol' parameter of SVC must be a float in the range (0.0, inf). Got 0 instead."
     ]
    }
   ],
   "source": [
    "time_start_kfold = time.time()\n",
    "searcher_kfold.fit(train_set, train_labels)\n",
    "time_end_kfold = time.time()\n",
    "\n",
    "kfold_best_params_rnd_cv = searcher_kfold.get_best_params()\n",
    "kfold_best_score_rnd_cv = searcher_kfold.get_best_score()\n",
    "kfold_best_model_rnd_cv = searcher_kfold.get_best_model()\n",
    "\n",
    "kfold_best_model_rnd_cv.fit(train_set, train_labels)\n",
    "kfold_test_predictions_rnd_cv = kfold_best_model_rnd_cv.predict(test_set)\n",
    "kfold_test_accuracy_rnd_cv = accuracy_score(test_labels, kfold_test_predictions_rnd_cv)\n",
    "\n",
    "joblib.dump(kfold_best_model_rnd_cv, MODELPATH + '04_SVM_kfold_rnd_cv.pkl')\n",
    "save_model_as_sklearn(filename='04_SVM_kfold_rnd_cv_sklearn.pkl', parameters=kfold_best_params_rnd_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3ca41c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>Best Parameters Found</h3>\n",
       "<ul>\n",
       "<li>C: 2</li><li>class_weight: balanced</li><li>degree: 4</li><li>gamma: 0.07</li><li>kernel: poly</li><li>max_iter: 3900.0</li><li>tol: 0.1</li>\n",
       "</ul>\n",
       "<h3>Model Performance:</h3>\n",
       "<ul>\n",
       "    <li>Validation Accuracy: <b>76.71%</b></li>\n",
       "    <li>Test Accuracy: <b>71.43%</b></li>\n",
       "</ul>\n",
       "<p>Time taken: <b>890.36 .Sec</b></p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_print(kfold_best_params_rnd_cv, kfold_best_score_rnd_cv, kfold_test_accuracy_rnd_cv, time_end_kfold, time_start_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158689fb",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with  Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a18a68b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomized Search CV...\n",
      "Evaluating parameter set 1/80\n",
      "  Average CV score: 0.6401\n",
      "Evaluating parameter set 2/80\n",
      "  Average CV score: 0.6401\n",
      "Evaluating parameter set 3/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 4/80\n",
      "  Average CV score: 0.6775\n",
      "Evaluating parameter set 5/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 6/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 7/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 8/80\n",
      "  Average CV score: 0.7492\n",
      "Evaluating parameter set 9/80\n",
      "  Average CV score: 0.6401\n",
      "Evaluating parameter set 10/80\n",
      "  Average CV score: 0.7231\n",
      "Evaluating parameter set 11/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 12/80\n",
      "  Average CV score: 0.6775\n",
      "Evaluating parameter set 13/80\n",
      "  Average CV score: 0.7492\n",
      "Evaluating parameter set 14/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 15/80\n",
      "  Average CV score: 0.7231\n",
      "Evaluating parameter set 16/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 17/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 18/80\n",
      "  Average CV score: 0.6401\n",
      "Evaluating parameter set 19/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 20/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 21/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 22/80\n",
      "  Average CV score: 0.6090\n",
      "Evaluating parameter set 23/80\n",
      "  Average CV score: 0.7426\n",
      "Evaluating parameter set 24/80\n",
      "  Average CV score: 0.7475\n",
      "Evaluating parameter set 25/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 26/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 27/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 28/80\n",
      "  Average CV score: 0.7263\n",
      "Evaluating parameter set 29/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 30/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 31/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 32/80\n",
      "  Average CV score: 0.6434\n",
      "Evaluating parameter set 33/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 34/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 35/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 36/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 37/80\n",
      "  Average CV score: 0.7475\n",
      "Evaluating parameter set 38/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 39/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 40/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 41/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 42/80\n",
      "  Average CV score: 0.7540\n",
      "Evaluating parameter set 43/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 44/80\n",
      "  Average CV score: 0.7426\n",
      "Evaluating parameter set 45/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 46/80\n",
      "  Average CV score: 0.6937\n",
      "Evaluating parameter set 47/80\n",
      "  Average CV score: 0.7394\n",
      "Evaluating parameter set 48/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 49/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 50/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 51/80\n",
      "  Average CV score: 0.7475\n",
      "Evaluating parameter set 52/80\n",
      "  Average CV score: 0.6955\n",
      "Evaluating parameter set 53/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 54/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 55/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 56/80\n",
      "  Average CV score: 0.6775\n",
      "Evaluating parameter set 57/80\n",
      "  Average CV score: 0.7426\n",
      "Evaluating parameter set 58/80\n",
      "  Average CV score: 0.7231\n",
      "Evaluating parameter set 59/80\n",
      "  Average CV score: 0.7426\n",
      "Evaluating parameter set 60/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 61/80\n",
      "  Average CV score: 0.6922\n",
      "Evaluating parameter set 62/80\n",
      "  Average CV score: 0.6090\n",
      "Evaluating parameter set 63/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 64/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 65/80\n",
      "  Average CV score: 0.7426\n",
      "Evaluating parameter set 66/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 67/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 68/80\n",
      "  Average CV score: 0.3665\n",
      "Evaluating parameter set 69/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 70/80\n",
      "  Average CV score: 0.7393\n",
      "Evaluating parameter set 71/80\n",
      "  Average CV score: 0.6775\n",
      "Evaluating parameter set 72/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 73/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 74/80\n",
      "  Average CV score: 0.6434\n",
      "Evaluating parameter set 75/80\n",
      "  Average CV score: 0.6335\n",
      "Evaluating parameter set 76/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 77/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 78/80\n",
      "  Average CV score: 0.7280\n",
      "Evaluating parameter set 79/80\n",
      "  Average CV score: 0.5811\n",
      "Evaluating parameter set 80/80\n",
      "  Average CV score: 0.7476\n",
      "Randomized Search CV complete.\n",
      "Best parameters found: {'tol': np.float64(0.1), 'max_iter': 5000, 'kernel': 'rbf', 'gamma': np.float64(0.01), 'class_weight': 'balanced', 'C': np.float64(1000.0)}\n",
      "Best CV score: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/05_SVM_strat_rnd_cv.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_start_strat = time.time()\n",
    "searcher_strat.fit(train_set, train_labels)\n",
    "time_end_strat = time.time()\n",
    "\n",
    "strat_best_params_rnd_cv = searcher_strat.get_best_params()\n",
    "strat_best_score_rnd_cv = searcher_strat.get_best_score()\n",
    "strat_best_model_rnd_cv = searcher_strat.get_best_model()\n",
    "\n",
    "strat_best_model_rnd_cv.fit(train_set, train_labels)\n",
    "strat_test_predictions_rnd_cv = strat_best_model_rnd_cv.predict(test_set)\n",
    "strat_test_accuracy_rnd_cv = accuracy_score(test_labels, strat_test_predictions_rnd_cv)\n",
    "\n",
    "joblib.dump(strat_best_model_rnd_cv, MODELPATH + '05_SVM_strat_rnd_cv.pkl')\n",
    "save_model_as_sklearn(filename='05_SVM_strat_rnd_cv_sklearn.pkl', parameters=strat_best_params_rnd_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88b12a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>Best Parameters Found</h3>\n",
       "<ul>\n",
       "<li>tol: 0.1</li><li>max_iter: 5000</li><li>kernel: rbf</li><li>gamma: 0.01</li><li>class_weight: balanced</li><li>C: 1000.0</li>\n",
       "</ul>\n",
       "<h3>Model Performance:</h3>\n",
       "<ul>\n",
       "    <li>Validation Accuracy: <b>75.40%</b></li>\n",
       "    <li>Test Accuracy: <b>70.78%</b></li>\n",
       "</ul>\n",
       "<p>Time taken: <b>1864.41 .Sec</b></p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_print(strat_best_params_rnd_cv, strat_best_score_rnd_cv, strat_test_accuracy_rnd_cv, time_end_strat, time_start_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b8a0a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2474c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomized Search CV...\n",
      "Evaluating parameter set 1/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 2/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 3/40\n",
      "  Average CV score: 0.7459\n",
      "Evaluating parameter set 4/40\n",
      "  Average CV score: 0.7443\n",
      "Evaluating parameter set 5/40\n",
      "  Average CV score: 0.7508\n",
      "Evaluating parameter set 6/40\n",
      "  Average CV score: 0.7508\n",
      "Evaluating parameter set 7/40\n",
      "  Average CV score: 0.7508\n",
      "Evaluating parameter set 8/40\n",
      "  Average CV score: 0.7362\n",
      "Evaluating parameter set 9/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 10/40\n",
      "  Average CV score: 0.7166\n",
      "Evaluating parameter set 11/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 12/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 13/40\n",
      "  Average CV score: 0.7410\n",
      "Evaluating parameter set 14/40\n",
      "  Average CV score: 0.7410\n",
      "Evaluating parameter set 15/40\n",
      "  Average CV score: 0.7541\n",
      "Evaluating parameter set 16/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 17/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 18/40\n",
      "  Average CV score: 0.7248\n",
      "Evaluating parameter set 19/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 20/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 21/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 22/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 23/40\n",
      "  Average CV score: 0.7329\n",
      "Evaluating parameter set 24/40\n",
      "  Average CV score: 0.7524\n",
      "Evaluating parameter set 25/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 26/40\n",
      "  Average CV score: 0.6922\n",
      "Evaluating parameter set 27/40\n",
      "  Average CV score: 0.7410\n",
      "Evaluating parameter set 28/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 29/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 30/40\n",
      "  Average CV score: 0.0000\n",
      "Evaluating parameter set 31/40\n",
      "  Average CV score: 0.6922\n",
      "Evaluating parameter set 32/40\n",
      "  Average CV score: 0.3664\n",
      "Evaluating parameter set 33/40\n",
      "  Average CV score: 1.0000\n",
      "Evaluating parameter set 34/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 35/40\n",
      "  Average CV score: 0.7410\n",
      "Evaluating parameter set 36/40\n",
      "  Average CV score: 1.0000\n",
      "Evaluating parameter set 37/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 38/40\n",
      "  Average CV score: 0.0000\n",
      "Evaluating parameter set 39/40\n",
      "  Average CV score: 0.6336\n",
      "Evaluating parameter set 40/40\n",
      "  Average CV score: 0.7541\n",
      "Randomized Search CV complete.\n",
      "Best parameters found: {'tol': np.float64(1e-07), 'max_iter': 1000, 'kernel': 'sigmoid', 'gamma': np.float64(0.001), 'coef0': np.float64(-0.5555555555555556), 'class_weight': 'balanced', 'C': np.float64(0.1)}\n",
      "Best CV score: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/06_SVM_loocv_rnd_cv.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_start_loo = time.time()\n",
    "searcher_loocv.fit(train_set, train_labels)\n",
    "time_end_loo = time.time()\n",
    "\n",
    "loocv_best_params_rnd_cv = searcher_loocv.get_best_params()\n",
    "loocv_best_score_rnd_cv = searcher_loocv.get_best_score()\n",
    "loocv_best_model_rnd_cv = searcher_loocv.get_best_model()\n",
    "\n",
    "loocv_best_model_rnd_cv.fit(train_set, train_labels)\n",
    "loocv_test_predictions_rnd_cv = loocv_best_model_rnd_cv.predict(test_set)\n",
    "loocv_test_accuracy_rnd_cv = accuracy_score(test_labels, loocv_test_predictions_rnd_cv)\n",
    "\n",
    "joblib.dump(loocv_best_model_rnd_cv, MODELPATH + '06_SVM_loocv_rnd_cv.pkl')\n",
    "save_model_as_sklearn(filename='06_SVM_loocv_rnd_cv_sklearn.pkl', parameters=loocv_best_params_rnd_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e41be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>Best Parameters Found</h3>\n",
       "<ul>\n",
       "<li>tol: 1e-07</li><li>max_iter: 1000</li><li>kernel: sigmoid</li><li>gamma: 0.001</li><li>coef0: -0.5555555555555556</li><li>class_weight: balanced</li><li>C: 0.1</li>\n",
       "</ul>\n",
       "<h3>Model Performance:</h3>\n",
       "<ul>\n",
       "    <li>Validation Accuracy: <b>100.00%</b></li>\n",
       "    <li>Test Accuracy: <b>72.08%</b></li>\n",
       "</ul>\n",
       "<p>Time taken: <b>112.21 .Sec</b></p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_print(loocv_best_params_rnd_cv, loocv_best_score_rnd_cv, loocv_test_accuracy_rnd_cv, time_end_loo, time_start_loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2f34f",
   "metadata": {},
   "source": [
    "# Further Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fb8531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridCV = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.8, 0.9, 1, 1.1, 1.2, 2], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "573c8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuMLGridSearchCV:\n",
    "\n",
    "    def __init__(self, model, param_grid, cv=None, random_state=42, verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize the GridSearchCV.\n",
    "\n",
    "        Args:\n",
    "        model (object): The machine learning model to tune. Must have `fit` and `score` methods.\n",
    "        param_grid (dict): Dictionary with parameters names (str) as keys and lists of parameter settings to try as values.\n",
    "        cv (object): Cross-validation splitting strategy.\n",
    "                     Should be one of KFold, StratifiedKFold, or LeaveOneOut.\n",
    "                     If None, defaults to 5-fold KFold.\n",
    "        random_state (int): Random state for reproducibility.\n",
    "        verbose (bool): Whether to print progress messages. Defaults to False.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv if cv is not None else KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.results = []\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def _parameter_comb(self):\n",
    "        \"\"\"Sample parameter combinations from the given distributions.\"\"\"\n",
    "        for params in ParameterGrid(self.param_grid):\n",
    "            yield params\n",
    "\n",
    "    def _train_and_evaluate(self, X, y, param_comb):\n",
    "        \"\"\"Train and evaluate a model with given parameters using the chosen CV method.\"\"\"\n",
    "        scores = []\n",
    "        if isinstance(self.cv, LeaveOneOut):\n",
    "            for i, (train_index, val_index) in enumerate(self.cv.split(X, y)):\n",
    "                if self.verbose:\n",
    "                    print(f\" Training and evaluating sample {i+1}/{len(X)}...\")\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "                self.model.set_params(**param_comb)\n",
    "                self.model.fit(X_train, y_train)\n",
    "                score = self.model.score(X_val, y_val)\n",
    "                scores.append(score)\n",
    "        else:\n",
    "            for fold, (train_index, val_index) in enumerate(self.cv.split(X, y)):\n",
    "                if self.verbose:\n",
    "                    print(f\" Training and evaluating fold {fold+1}/{self.cv.get_n_splits(X, y)}...\")\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "                self.model.set_params(**param_comb)\n",
    "                self.model.fit(X_train, y_train)\n",
    "                score = self.model.score(X_val, y_val)\n",
    "                scores.append(score)\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the parameter grid to the data.\"\"\"\n",
    "        print(\"Starting Grid Search CV...\")\n",
    "        for i, param_comb in enumerate(self._parameter_comb()):\n",
    "            if self.verbose:\n",
    "                print(f\"Processing parameter combination {i+1}/{len(list(ParameterGrid(self.param_grid)))}: {param_comb}\")\n",
    "            else:\n",
    "                print(f\"Processing parameter combination {i+1}/{len(list(ParameterGrid(self.param_grid)))}...\")\n",
    "            avg_score = self._train_and_evaluate(X, y, param_comb)\n",
    "            print(f\"Average CV score: {avg_score:.4f}\")\n",
    "            self.results.append({'params': param_comb, 'score': avg_score})\n",
    "\n",
    "        best_result = max(self.results, key=lambda x: x['score'])\n",
    "        self.best_params = best_result['params']\n",
    "        self.best_score = best_result['score']\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        print(\"Randomized Search CV complete.\")\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        print(f\"Best CV score: {self.best_score:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, train_set, train_labels, test_set):\n",
    "        \"\"\"Predict using the best found parameters.\"\"\"\n",
    "        print(\"Training final model with best parameters...\")\n",
    "        final_model = self.model.set_params(**self.best_params)\n",
    "        final_model.fit(train_set, train_labels)\n",
    "        print(\"Final model training complete.\")\n",
    "        return final_model.predict(test_set)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Score the model's performance.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def get_best_params(self):\n",
    "        \"\"\"Return the best parameters found by the grid search.\"\"\"\n",
    "        return self.best_params\n",
    "\n",
    "    def get_best_score(self):\n",
    "        \"\"\"Return the best score found by the grid search.\"\"\"\n",
    "        return self.best_score\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Return the results of the grid search.\"\"\"\n",
    "        return self.results\n",
    "\n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best model found by the grid search.\"\"\"\n",
    "        return self.model.set_params(**self.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12107029",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 20\n",
    "N_SPLITS = 5\n",
    "RND_STATE = 42\n",
    "\n",
    "svc_rnd_cv = SVC()\n",
    "\n",
    "fold_strategy_kfold = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RND_STATE)\n",
    "fold_strategy_strat = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RND_STATE)\n",
    "fold_strategy_loocv = LeaveOneOut()\n",
    "\n",
    "searcher_kfold_grid = CuMLGridSearchCV(\n",
    "    model=svc_rnd_cv, \n",
    "    param_grid=param_gridCV, \n",
    "    cv=fold_strategy_kfold, \n",
    "    random_state=RND_STATE,\n",
    "    )\n",
    "\n",
    "searcher_strat_grid = CuMLGridSearchCV(\n",
    "    model=svc_rnd_cv,\n",
    "    param_grid=param_gridCV,\n",
    "    cv=fold_strategy_strat,\n",
    "    random_state=RND_STATE,\n",
    "    )\n",
    "\n",
    "searcher_loocv_grid = CuMLGridSearchCV(\n",
    "    model=svc_rnd_cv,\n",
    "    param_grid=param_gridCV,\n",
    "    cv=fold_strategy_loocv,\n",
    "    random_state=RND_STATE,\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2869cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start_kfold_grid = time.time()\n",
    "searcher_kfold_grid.fit(train_set, train_labels)\n",
    "time_end_kfold_grid = time.time()\n",
    "\n",
    "kfold_best_params_grid_cv = searcher_kfold_grid.get_best_params()\n",
    "kfold_best_score_grid_cv = searcher_kfold_grid.get_best_score()\n",
    "kfold_best_model_grid_cv = searcher_kfold_grid.get_best_model()\n",
    "\n",
    "kfold_best_model_grid_cv.fit(train_set, train_labels)\n",
    "kfold_test_predictions_grid_cv = kfold_best_model_grid_cv.predict(test_set)\n",
    "kfold_test_accuracy_grid_cv = accuracy_score(test_labels, kfold_test_predictions_grid_cv)\n",
    "\n",
    "joblib.dump(kfold_best_model_grid_cv, MODELPATH + '07_SVM_kfold_grid_cv.pkl')\n",
    "save_model_as_sklearn(filename='07_SVM_kfold_grid_cv_sklearn.pkl', parameters=kfold_best_params_grid_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b8b0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_print(kfold_best_params_grid_cv, kfold_best_score_grid_cv, kfold_test_accuracy_grid_cv, time_end_kfold_grid, time_start_kfold_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start_strat_grid = time.time()\n",
    "searcher_strat_grid.fit(train_set, train_labels)\n",
    "time_end_strat_grid = time.time()\n",
    "\n",
    "strat_best_params_grid_cv = searcher_strat_grid.get_best_params()\n",
    "strat_best_score_grid_cv = searcher_strat_grid.get_best_score()\n",
    "strat_best_model_grid_cv = searcher_strat_grid.get_best_model()\n",
    "\n",
    "strat_best_model_grid_cv.fit(train_set, train_labels)\n",
    "strat_test_predictions_grid_cv = strat_best_model_grid_cv.predict(test_set)\n",
    "strat_test_accuracy_grid_cv = accuracy_score(test_labels, strat_test_predictions_grid_cv)\n",
    "\n",
    "joblib.dump(strat_best_model_grid_cv, MODELPATH + '08_SVM_strat_grid_cv.pkl')\n",
    "save_model_as_sklearn(filename='08_SVM_strat_grid_cv_sklearn.pkl', parameters=strat_best_params_grid_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_print(strat_best_params_grid_cv, strat_best_score_grid_cv, strat_test_accuracy_grid_cv, time_end_strat_grid, time_start_strat_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_loo_grid = time.time()\n",
    "searcher_loocv_grid.fit(train_set, train_labels)\n",
    "end_time_loo_grid = time.time()\n",
    "\n",
    "loocv_best_params_grid_cv = searcher_loocv_grid.get_best_params()\n",
    "loocv_best_score_grid_cv = searcher_loocv_grid.get_best_score()\n",
    "loocv_best_model_grid_cv = searcher_loocv_grid.get_best_model()\n",
    "\n",
    "loocv_best_model_grid_cv.fit(train_set, train_labels)\n",
    "loocv_test_predictions_grid_cv = loocv_best_model_grid_cv.predict(test_set)\n",
    "loocv_test_accuracy_grid_cv = accuracy_score(test_labels, loocv_test_predictions_grid_cv)\n",
    "\n",
    "joblib.dump(loocv_best_model_grid_cv, MODELPATH + '09_SVM_loocv_grid_cv.pkl')\n",
    "save_model_as_sklearn(filename='09_SVM_loocv_grid_cv_sklearn.pkl', parameters=loocv_best_params_grid_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_print(loocv_best_params_grid_cv, loocv_best_score_grid_cv, loocv_test_accuracy_grid_cv, end_time_loo_grid, start_time_loo_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
