{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477ff41",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "### with Hyperparameter Tuning\n",
    "\n",
    "### Hinweis:\n",
    "Anders als in den Praktika und Vorlesungen verwenden wir hier nicht `Scikit-learn`, sondern die Bibliothek `cuML` (CUDA Machine Learning). Diese ermöglicht es SVMs auf der GPU zu trainieren, was den Trainingsprozess extrem beschleunigt. An der Herangehensweise und der Art, wie wir die Hyperparameter tunen, ändert sich dadurch nichts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "from cuml.svm import SVC\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "from cuml.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "DATAPATH = '../Data/'\n",
    "MODELPATH = '../Data/Models/SVM/'\n",
    "MODELPATHSKLEARN = '../Data/Models/SVM/SVM_sklearn/'\n",
    "\n",
    "train_set = cudf.read_csv(DATAPATH + 'train_set.csv')\n",
    "train_labels = cudf.read_csv(DATAPATH + 'train_labels.csv')\n",
    "test_set = cudf.read_csv(DATAPATH + 'test_set.csv')\n",
    "test_labels = cudf.read_csv(DATAPATH + 'test_labels.csv')\n",
    "\n",
    "train_labels = train_labels.squeeze()\n",
    "test_labels = test_labels.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca5981",
   "metadata": {},
   "source": [
    "# WITHOUT Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec5bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467246055603\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "test_pred = clf.predict(test_set)\n",
    "accuracy_score = accuracy_score(test_labels, test_pred)\n",
    "\n",
    "joblib.dump(clf, MODELPATH + 'SVM_no_hyper.pkl')\n",
    "\n",
    "print(f'Accuracy: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590745c",
   "metadata": {},
   "source": [
    "# With (Random) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a945556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True), \n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'degree': [2, 3, 4, 5, 6], # Macht natrülich nur Sinn, wenn degree > 1 da sonst linear\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'C': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'tol': np.logspace(np.log10(0.0000001), np.log10(0.1), 7, endpoint=True),\n",
    "        'gamma': np.logspace(np.log10(0.001), np.log10(1000), 7, endpoint=True),\n",
    "        'coef0': np.linspace(-1, 1, 10),\n",
    "        'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "        'class_weight': ['balanced'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1977591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_sampl.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 100\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_sampled_params = []\n",
    "for params in param_distributions:\n",
    "    sampler = ParameterSampler(params, n_iter=n_iter, random_state=42)\n",
    "    sampled_params = list(sampler)\n",
    "    all_sampled_params.extend(sampled_params)\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for params in all_sampled_params:\n",
    "    try:\n",
    "        clf.set_params(**params)\n",
    "        clf.fit(train_set, train_labels)\n",
    "        predictions = clf.predict(test_set)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        counter += 1\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping invalid parameter combination: {params}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels) \n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_sampl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b964d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tol': np.float64(0.1), 'max_iter': 4000, 'kernel': 'poly', 'gamma': np.float64(0.1), 'degree': 5, 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "Best accuracy: 0.7662337422370911\n",
      "Time taken: 39.86 seconds\n",
      "Test accuracy with best model: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Test accuracy with best model: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39eadda",
   "metadata": {},
   "source": [
    "# Further Hyperparameter Tuning with Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09520c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Models/SVM/SVM_para_grid.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.01, 0.1, 0.8, 0.9, 1, 1.1, 1.2, 2, 5, 10], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    },\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(train_set, train_labels)\n",
    "    predictions = clf.predict(test_set)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params    \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "best_model = SVC(**best_params)\n",
    "best_model.fit(train_set, train_labels)\n",
    "test_predictions = best_model.predict(test_set)\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "joblib.dump(best_model, MODELPATH + 'SVM_para_grid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8831b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GRID SEARCH RESULTS\n",
      "==================================================\n",
      "\n",
      "Best Parameters Found:\n",
      "  C: 1.2\n",
      "  class_weight: balanced\n",
      "  degree: 4\n",
      "  gamma: 0.07\n",
      "  kernel: poly\n",
      "  max_iter: 3900.0\n",
      "  tol: 0.1\n",
      "\n",
      "Model Performance:\n",
      "  Validation Accuracy: 78.57%\n",
      "  Test Accuracy: 66.88%\n",
      "\n",
      "Training Time: 442.50 seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Validation Accuracy: {best_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"\\nTraining Time: {end_time - start_time:.2f} seconds\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bbc59",
   "metadata": {},
   "source": [
    "# (Random) Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f26ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuMLRandomizedSearchCV:\n",
    "\n",
    "    model = SVC()\n",
    "\n",
    "    def __init__(self, param_distributions, n_iter=10, cv_method='kfold', k=5, random_state=42):\n",
    "        self.param_distributions = param_distributions\n",
    "        self.n_iter = n_iter\n",
    "        self.cv_method = cv_method\n",
    "        self.k = k\n",
    "        self.random_state = random_state\n",
    "        self.results = []\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def _sample_parameters(self):\n",
    "        \"\"\"Sample parameter combinations from the given distributions.\"\"\"\n",
    "        for param_distribution in self.param_distributions:\n",
    "            sampler = ParameterSampler(param_distribution, n_iter=self.n_iter, random_state=self.random_state)\n",
    "            for sampled_params in sampler:\n",
    "                yield sampled_params\n",
    "\n",
    "    def _train_and_evaluate(self, X, y, sampled_params):\n",
    "        \"\"\"Train and evaluate a model with given parameters using the chosen CV method.\"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        if self.cv_method == 'kfold':\n",
    "            scores = self._kfold_cv(X, y, sampled_params)\n",
    "        elif self.cv_method == 'stratified':\n",
    "            scores = self._stratified_kfold_cv(X, y, sampled_params)\n",
    "        elif self.cv_method == 'loocv':\n",
    "            scores = self._loocv(X, y, sampled_params)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cv_method. Choose 'kfold', 'stratified', or 'loocv'.\")\n",
    "        \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def _kfold_cv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform k-fold cross-validation.\"\"\"\n",
    "        from sklearn.model_selection import KFold\n",
    "\n",
    "        kf = KFold(n_splits=self.k, shuffle=True, random_state=self.random_state)\n",
    "        scores = []\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "            print(f\"  Training and evaluating fold {fold+1}/{self.k}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def _stratified_kfold_cv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform stratified k-fold cross-validation.\"\"\"\n",
    "        from cuml.model_selection import StratifiedKFold\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=self.k, random_state=self.random_state, shuffle=True)\n",
    "        scores = []\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "            print(f\"  Training and evaluating fold {fold+1}/{self.k}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def _loocv(self, X, y, sampled_params):\n",
    "        \"\"\"Perform Leave-One-Out cross-validation.\"\"\"\n",
    "        from sklearn.model_selection import LeaveOneOut\n",
    "        \n",
    "        loo = LeaveOneOut()\n",
    "        scores = []\n",
    "        for i, (train_index, val_index) in enumerate(loo.split(X)):\n",
    "            print(f\"  Training and evaluating sample {i+1}/{len(X)}...\")\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            CuMLRandomizedSearchCV.model.set_params(**sampled_params)\n",
    "            CuMLRandomizedSearchCV.model.fit(X_train, y_train)\n",
    "            score = CuMLRandomizedSearchCV.model.score(X_val, y_val)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the randomized search CV to the data.\"\"\"\n",
    "        print(\"Starting Randomized Search CV...\")\n",
    "        for i, sampled_params in enumerate(self._sample_parameters()):\n",
    "            print(f\"Evaluating parameter set {i+1}/{self.n_iter * len(self.param_distributions)}: {sampled_params}\")\n",
    "            avg_score = self._train_and_evaluate(X, y, sampled_params)\n",
    "            print(f\"  Average CV score: {avg_score:.4f}\")\n",
    "            self.results.append({'params': sampled_params, 'score': avg_score})\n",
    "\n",
    "        best_result = max(self.results, key=lambda x: x['score'])\n",
    "        self.best_params = best_result['params']\n",
    "        self.best_score = best_result['score']\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        print(\"Randomized Search CV complete.\")\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        print(f\"Best CV score: {self.best_score:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, train_set, train_labels, test_set):\n",
    "        \"\"\"Predict using the best found parameters.\"\"\"\n",
    "        print(\"Training final model with best parameters...\")\n",
    "        final_model = SVC(**self.best_params)\n",
    "        final_model.fit(train_set, train_labels)\n",
    "        print(\"Final model training complete.\")\n",
    "        return final_model.predict(test_set)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Score the model's performance.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        \"\"\"Return the best parameters found by the randomized search.\"\"\"\n",
    "        return self.best_params\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        \"\"\"Return the best score found by the randomized search.\"\"\"\n",
    "        return self.best_score\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Return the results of the randomized search.\"\"\"\n",
    "        return self.results\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best model found by the randomized search.\"\"\"\n",
    "        return SVC(**self.best_params)\n",
    "    \n",
    "    def save_best_model(self, train_set, train_labels):\n",
    "        \"\"\"Save the best model to a file.\"\"\"\n",
    "        final_model = SVC(**self.best_params)\n",
    "        final_model.fit(train_set, train_labels)\n",
    "        joblib.dump(final_model, DATAPATH + 'SVM_rnd_search_CV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3116940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomized Search CV...\n",
      "Evaluating parameter set 1/80: {'tol': np.float64(1e-07), 'max_iter': 5000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(1.0)}\n",
      "  Training and evaluating sample 1/800...\n",
      "  Training and evaluating sample 2/800...\n",
      "  Training and evaluating sample 3/800...\n",
      "  Training and evaluating sample 4/800...\n",
      "  Training and evaluating sample 5/800...\n",
      "  Training and evaluating sample 6/800...\n",
      "  Training and evaluating sample 7/800...\n",
      "  Training and evaluating sample 8/800...\n",
      "  Training and evaluating sample 9/800...\n",
      "  Training and evaluating sample 10/800...\n",
      "  Training and evaluating sample 11/800...\n",
      "  Training and evaluating sample 12/800...\n",
      "  Training and evaluating sample 13/800...\n",
      "  Training and evaluating sample 14/800...\n",
      "  Training and evaluating sample 15/800...\n",
      "  Training and evaluating sample 16/800...\n",
      "  Training and evaluating sample 17/800...\n",
      "  Training and evaluating sample 18/800...\n",
      "  Training and evaluating sample 19/800...\n",
      "  Training and evaluating sample 20/800...\n",
      "  Training and evaluating sample 21/800...\n",
      "  Training and evaluating sample 22/800...\n",
      "  Training and evaluating sample 23/800...\n",
      "  Training and evaluating sample 24/800...\n",
      "  Training and evaluating sample 25/800...\n",
      "  Training and evaluating sample 26/800...\n",
      "  Training and evaluating sample 27/800...\n",
      "  Training and evaluating sample 28/800...\n",
      "  Training and evaluating sample 29/800...\n",
      "  Training and evaluating sample 30/800...\n",
      "  Training and evaluating sample 31/800...\n",
      "  Training and evaluating sample 32/800...\n",
      "  Training and evaluating sample 33/800...\n",
      "  Training and evaluating sample 34/800...\n",
      "  Training and evaluating sample 35/800...\n",
      "  Training and evaluating sample 36/800...\n",
      "  Training and evaluating sample 37/800...\n",
      "  Training and evaluating sample 38/800...\n",
      "  Training and evaluating sample 39/800...\n",
      "  Training and evaluating sample 40/800...\n",
      "  Training and evaluating sample 41/800...\n",
      "  Training and evaluating sample 42/800...\n",
      "  Training and evaluating sample 43/800...\n",
      "  Training and evaluating sample 44/800...\n",
      "  Training and evaluating sample 45/800...\n",
      "  Training and evaluating sample 46/800...\n",
      "  Training and evaluating sample 47/800...\n",
      "  Training and evaluating sample 48/800...\n",
      "  Training and evaluating sample 49/800...\n",
      "  Training and evaluating sample 50/800...\n",
      "  Training and evaluating sample 51/800...\n",
      "  Training and evaluating sample 52/800...\n",
      "  Training and evaluating sample 53/800...\n",
      "  Training and evaluating sample 54/800...\n",
      "  Training and evaluating sample 55/800...\n",
      "  Training and evaluating sample 56/800...\n",
      "  Training and evaluating sample 57/800...\n",
      "  Training and evaluating sample 58/800...\n",
      "  Training and evaluating sample 59/800...\n",
      "  Training and evaluating sample 60/800...\n",
      "  Training and evaluating sample 61/800...\n",
      "  Training and evaluating sample 62/800...\n",
      "  Training and evaluating sample 63/800...\n",
      "  Training and evaluating sample 64/800...\n",
      "  Training and evaluating sample 65/800...\n",
      "  Training and evaluating sample 66/800...\n",
      "  Training and evaluating sample 67/800...\n",
      "  Training and evaluating sample 68/800...\n",
      "  Training and evaluating sample 69/800...\n",
      "  Training and evaluating sample 70/800...\n",
      "  Training and evaluating sample 71/800...\n",
      "  Training and evaluating sample 72/800...\n",
      "  Training and evaluating sample 73/800...\n",
      "  Training and evaluating sample 74/800...\n",
      "  Training and evaluating sample 75/800...\n",
      "  Training and evaluating sample 76/800...\n",
      "  Training and evaluating sample 77/800...\n",
      "  Training and evaluating sample 78/800...\n",
      "  Training and evaluating sample 79/800...\n",
      "  Training and evaluating sample 80/800...\n",
      "  Training and evaluating sample 81/800...\n",
      "  Training and evaluating sample 82/800...\n",
      "  Training and evaluating sample 83/800...\n",
      "  Training and evaluating sample 84/800...\n",
      "  Training and evaluating sample 85/800...\n",
      "  Training and evaluating sample 86/800...\n",
      "  Training and evaluating sample 87/800...\n",
      "  Training and evaluating sample 88/800...\n",
      "  Training and evaluating sample 89/800...\n",
      "  Training and evaluating sample 90/800...\n",
      "  Training and evaluating sample 91/800...\n",
      "  Training and evaluating sample 92/800...\n",
      "  Training and evaluating sample 93/800...\n",
      "  Training and evaluating sample 94/800...\n",
      "  Training and evaluating sample 95/800...\n",
      "  Training and evaluating sample 96/800...\n",
      "  Training and evaluating sample 97/800...\n",
      "  Training and evaluating sample 98/800...\n",
      "  Training and evaluating sample 99/800...\n",
      "  Training and evaluating sample 100/800...\n",
      "  Training and evaluating sample 101/800...\n",
      "  Training and evaluating sample 102/800...\n",
      "  Training and evaluating sample 103/800...\n",
      "  Training and evaluating sample 104/800...\n",
      "  Training and evaluating sample 105/800...\n",
      "  Training and evaluating sample 106/800...\n",
      "  Training and evaluating sample 107/800...\n",
      "  Training and evaluating sample 108/800...\n",
      "  Training and evaluating sample 109/800...\n",
      "  Training and evaluating sample 110/800...\n",
      "  Training and evaluating sample 111/800...\n",
      "  Training and evaluating sample 112/800...\n",
      "  Training and evaluating sample 113/800...\n",
      "  Training and evaluating sample 114/800...\n",
      "  Training and evaluating sample 115/800...\n",
      "  Training and evaluating sample 116/800...\n",
      "  Training and evaluating sample 117/800...\n",
      "  Training and evaluating sample 118/800...\n",
      "  Training and evaluating sample 119/800...\n",
      "  Training and evaluating sample 120/800...\n",
      "  Training and evaluating sample 121/800...\n",
      "  Training and evaluating sample 122/800...\n",
      "  Training and evaluating sample 123/800...\n",
      "  Training and evaluating sample 124/800...\n",
      "  Training and evaluating sample 125/800...\n",
      "  Training and evaluating sample 126/800...\n",
      "  Training and evaluating sample 127/800...\n",
      "  Training and evaluating sample 128/800...\n",
      "  Training and evaluating sample 129/800...\n",
      "  Training and evaluating sample 130/800...\n",
      "  Training and evaluating sample 131/800...\n",
      "  Training and evaluating sample 132/800...\n",
      "  Training and evaluating sample 133/800...\n",
      "  Training and evaluating sample 134/800...\n",
      "  Training and evaluating sample 135/800...\n",
      "  Training and evaluating sample 136/800...\n",
      "  Training and evaluating sample 137/800...\n",
      "  Training and evaluating sample 138/800...\n",
      "  Training and evaluating sample 139/800...\n",
      "  Training and evaluating sample 140/800...\n",
      "  Training and evaluating sample 141/800...\n",
      "  Training and evaluating sample 142/800...\n",
      "  Training and evaluating sample 143/800...\n",
      "  Training and evaluating sample 144/800...\n",
      "  Training and evaluating sample 145/800...\n",
      "  Training and evaluating sample 146/800...\n",
      "  Training and evaluating sample 147/800...\n",
      "  Training and evaluating sample 148/800...\n",
      "  Training and evaluating sample 149/800...\n",
      "  Training and evaluating sample 150/800...\n",
      "  Training and evaluating sample 151/800...\n",
      "  Training and evaluating sample 152/800...\n",
      "  Training and evaluating sample 153/800...\n",
      "  Training and evaluating sample 154/800...\n",
      "  Training and evaluating sample 155/800...\n",
      "  Training and evaluating sample 156/800...\n",
      "  Training and evaluating sample 157/800...\n",
      "  Training and evaluating sample 158/800...\n",
      "  Training and evaluating sample 159/800...\n",
      "  Training and evaluating sample 160/800...\n",
      "  Training and evaluating sample 161/800...\n",
      "  Training and evaluating sample 162/800...\n",
      "  Training and evaluating sample 163/800...\n",
      "  Training and evaluating sample 164/800...\n",
      "  Training and evaluating sample 165/800...\n",
      "  Training and evaluating sample 166/800...\n",
      "  Training and evaluating sample 167/800...\n",
      "  Training and evaluating sample 168/800...\n",
      "  Training and evaluating sample 169/800...\n",
      "  Training and evaluating sample 170/800...\n",
      "  Training and evaluating sample 171/800...\n",
      "  Training and evaluating sample 172/800...\n",
      "  Training and evaluating sample 173/800...\n",
      "  Training and evaluating sample 174/800...\n",
      "  Training and evaluating sample 175/800...\n",
      "  Training and evaluating sample 176/800...\n",
      "  Training and evaluating sample 177/800...\n",
      "  Training and evaluating sample 178/800...\n",
      "  Training and evaluating sample 179/800...\n",
      "  Training and evaluating sample 180/800...\n",
      "  Training and evaluating sample 181/800...\n",
      "  Training and evaluating sample 182/800...\n",
      "  Training and evaluating sample 183/800...\n",
      "  Training and evaluating sample 184/800...\n",
      "  Training and evaluating sample 185/800...\n",
      "  Training and evaluating sample 186/800...\n",
      "  Training and evaluating sample 187/800...\n",
      "  Training and evaluating sample 188/800...\n",
      "  Training and evaluating sample 189/800...\n",
      "  Training and evaluating sample 190/800...\n",
      "  Training and evaluating sample 191/800...\n",
      "  Training and evaluating sample 192/800...\n",
      "  Training and evaluating sample 193/800...\n",
      "  Training and evaluating sample 194/800...\n",
      "  Training and evaluating sample 195/800...\n",
      "  Training and evaluating sample 196/800...\n",
      "  Training and evaluating sample 197/800...\n",
      "  Training and evaluating sample 198/800...\n",
      "  Training and evaluating sample 199/800...\n",
      "  Training and evaluating sample 200/800...\n",
      "  Training and evaluating sample 201/800...\n",
      "  Training and evaluating sample 202/800...\n",
      "  Training and evaluating sample 203/800...\n",
      "  Training and evaluating sample 204/800...\n",
      "  Training and evaluating sample 205/800...\n",
      "  Training and evaluating sample 206/800...\n",
      "  Training and evaluating sample 207/800...\n",
      "  Training and evaluating sample 208/800...\n",
      "  Training and evaluating sample 209/800...\n",
      "  Training and evaluating sample 210/800...\n",
      "  Training and evaluating sample 211/800...\n",
      "  Training and evaluating sample 212/800...\n",
      "  Training and evaluating sample 213/800...\n",
      "  Training and evaluating sample 214/800...\n",
      "  Training and evaluating sample 215/800...\n",
      "  Training and evaluating sample 216/800...\n",
      "  Training and evaluating sample 217/800...\n",
      "  Training and evaluating sample 218/800...\n",
      "  Training and evaluating sample 219/800...\n",
      "  Training and evaluating sample 220/800...\n",
      "  Training and evaluating sample 221/800...\n",
      "  Training and evaluating sample 222/800...\n",
      "  Training and evaluating sample 223/800...\n",
      "  Training and evaluating sample 224/800...\n",
      "  Training and evaluating sample 225/800...\n",
      "  Training and evaluating sample 226/800...\n",
      "  Training and evaluating sample 227/800...\n",
      "  Training and evaluating sample 228/800...\n",
      "  Training and evaluating sample 229/800...\n",
      "  Training and evaluating sample 230/800...\n",
      "  Training and evaluating sample 231/800...\n",
      "  Training and evaluating sample 232/800...\n",
      "  Training and evaluating sample 233/800...\n",
      "  Training and evaluating sample 234/800...\n",
      "  Training and evaluating sample 235/800...\n",
      "  Training and evaluating sample 236/800...\n",
      "  Training and evaluating sample 237/800...\n",
      "  Training and evaluating sample 238/800...\n",
      "  Training and evaluating sample 239/800...\n",
      "  Training and evaluating sample 240/800...\n",
      "  Training and evaluating sample 241/800...\n",
      "  Training and evaluating sample 242/800...\n",
      "  Training and evaluating sample 243/800...\n",
      "  Training and evaluating sample 244/800...\n",
      "  Training and evaluating sample 245/800...\n",
      "  Training and evaluating sample 246/800...\n",
      "  Training and evaluating sample 247/800...\n",
      "  Training and evaluating sample 248/800...\n",
      "  Training and evaluating sample 249/800...\n",
      "  Training and evaluating sample 250/800...\n",
      "  Training and evaluating sample 251/800...\n",
      "  Training and evaluating sample 252/800...\n",
      "  Training and evaluating sample 253/800...\n",
      "  Training and evaluating sample 254/800...\n",
      "  Training and evaluating sample 255/800...\n",
      "  Training and evaluating sample 256/800...\n",
      "  Training and evaluating sample 257/800...\n",
      "  Training and evaluating sample 258/800...\n",
      "  Training and evaluating sample 259/800...\n",
      "  Training and evaluating sample 260/800...\n",
      "  Training and evaluating sample 261/800...\n",
      "  Training and evaluating sample 262/800...\n",
      "  Training and evaluating sample 263/800...\n",
      "  Training and evaluating sample 264/800...\n",
      "  Training and evaluating sample 265/800...\n",
      "  Training and evaluating sample 266/800...\n",
      "  Training and evaluating sample 267/800...\n",
      "  Training and evaluating sample 268/800...\n",
      "  Training and evaluating sample 269/800...\n",
      "  Training and evaluating sample 270/800...\n",
      "  Training and evaluating sample 271/800...\n",
      "  Training and evaluating sample 272/800...\n",
      "  Training and evaluating sample 273/800...\n",
      "  Training and evaluating sample 274/800...\n",
      "  Training and evaluating sample 275/800...\n",
      "  Training and evaluating sample 276/800...\n",
      "  Training and evaluating sample 277/800...\n",
      "  Training and evaluating sample 278/800...\n",
      "  Training and evaluating sample 279/800...\n",
      "  Training and evaluating sample 280/800...\n",
      "  Training and evaluating sample 281/800...\n",
      "  Training and evaluating sample 282/800...\n",
      "  Training and evaluating sample 283/800...\n",
      "  Training and evaluating sample 284/800...\n",
      "  Training and evaluating sample 285/800...\n",
      "  Training and evaluating sample 286/800...\n",
      "  Training and evaluating sample 287/800...\n",
      "  Training and evaluating sample 288/800...\n",
      "  Training and evaluating sample 289/800...\n",
      "  Training and evaluating sample 290/800...\n",
      "  Training and evaluating sample 291/800...\n",
      "  Training and evaluating sample 292/800...\n",
      "  Training and evaluating sample 293/800...\n",
      "  Training and evaluating sample 294/800...\n",
      "  Training and evaluating sample 295/800...\n",
      "  Training and evaluating sample 296/800...\n",
      "  Training and evaluating sample 297/800...\n",
      "  Training and evaluating sample 298/800...\n",
      "  Training and evaluating sample 299/800...\n",
      "  Training and evaluating sample 300/800...\n",
      "  Training and evaluating sample 301/800...\n",
      "  Training and evaluating sample 302/800...\n",
      "  Training and evaluating sample 303/800...\n",
      "  Training and evaluating sample 304/800...\n",
      "  Training and evaluating sample 305/800...\n",
      "  Training and evaluating sample 306/800...\n",
      "  Training and evaluating sample 307/800...\n",
      "  Training and evaluating sample 308/800...\n",
      "  Training and evaluating sample 309/800...\n",
      "  Training and evaluating sample 310/800...\n",
      "  Training and evaluating sample 311/800...\n",
      "  Training and evaluating sample 312/800...\n",
      "  Training and evaluating sample 313/800...\n",
      "  Training and evaluating sample 314/800...\n",
      "  Training and evaluating sample 315/800...\n",
      "  Training and evaluating sample 316/800...\n",
      "  Training and evaluating sample 317/800...\n",
      "  Training and evaluating sample 318/800...\n",
      "  Training and evaluating sample 319/800...\n",
      "  Training and evaluating sample 320/800...\n",
      "  Training and evaluating sample 321/800...\n",
      "  Training and evaluating sample 322/800...\n",
      "  Training and evaluating sample 323/800...\n",
      "  Training and evaluating sample 324/800...\n",
      "  Training and evaluating sample 325/800...\n",
      "  Training and evaluating sample 326/800...\n",
      "  Training and evaluating sample 327/800...\n",
      "  Training and evaluating sample 328/800...\n",
      "  Training and evaluating sample 329/800...\n",
      "  Training and evaluating sample 330/800...\n",
      "  Training and evaluating sample 331/800...\n",
      "  Training and evaluating sample 332/800...\n",
      "  Training and evaluating sample 333/800...\n",
      "  Training and evaluating sample 334/800...\n",
      "  Training and evaluating sample 335/800...\n",
      "  Training and evaluating sample 336/800...\n",
      "  Training and evaluating sample 337/800...\n",
      "  Training and evaluating sample 338/800...\n",
      "  Training and evaluating sample 339/800...\n",
      "  Training and evaluating sample 340/800...\n",
      "  Training and evaluating sample 341/800...\n",
      "  Training and evaluating sample 342/800...\n",
      "  Training and evaluating sample 343/800...\n",
      "  Training and evaluating sample 344/800...\n",
      "  Training and evaluating sample 345/800...\n",
      "  Training and evaluating sample 346/800...\n",
      "  Training and evaluating sample 347/800...\n",
      "  Training and evaluating sample 348/800...\n",
      "  Training and evaluating sample 349/800...\n",
      "  Training and evaluating sample 350/800...\n",
      "  Training and evaluating sample 351/800...\n",
      "  Training and evaluating sample 352/800...\n",
      "  Training and evaluating sample 353/800...\n",
      "  Training and evaluating sample 354/800...\n",
      "  Training and evaluating sample 355/800...\n",
      "  Training and evaluating sample 356/800...\n",
      "  Training and evaluating sample 357/800...\n",
      "  Training and evaluating sample 358/800...\n",
      "  Training and evaluating sample 359/800...\n",
      "  Training and evaluating sample 360/800...\n",
      "  Training and evaluating sample 361/800...\n",
      "  Training and evaluating sample 362/800...\n",
      "  Training and evaluating sample 363/800...\n",
      "  Training and evaluating sample 364/800...\n",
      "  Training and evaluating sample 365/800...\n",
      "  Training and evaluating sample 366/800...\n",
      "  Training and evaluating sample 367/800...\n",
      "  Training and evaluating sample 368/800...\n",
      "  Training and evaluating sample 369/800...\n",
      "  Training and evaluating sample 370/800...\n",
      "  Training and evaluating sample 371/800...\n",
      "  Training and evaluating sample 372/800...\n",
      "  Training and evaluating sample 373/800...\n",
      "  Training and evaluating sample 374/800...\n",
      "  Training and evaluating sample 375/800...\n",
      "  Training and evaluating sample 376/800...\n",
      "  Training and evaluating sample 377/800...\n",
      "  Training and evaluating sample 378/800...\n",
      "  Training and evaluating sample 379/800...\n",
      "  Training and evaluating sample 380/800...\n",
      "  Training and evaluating sample 381/800...\n",
      "  Training and evaluating sample 382/800...\n",
      "  Training and evaluating sample 383/800...\n",
      "  Training and evaluating sample 384/800...\n",
      "  Training and evaluating sample 385/800...\n",
      "  Training and evaluating sample 386/800...\n",
      "  Training and evaluating sample 387/800...\n",
      "  Training and evaluating sample 388/800...\n",
      "  Training and evaluating sample 389/800...\n",
      "  Training and evaluating sample 390/800...\n",
      "  Training and evaluating sample 391/800...\n",
      "  Training and evaluating sample 392/800...\n",
      "  Training and evaluating sample 393/800...\n",
      "  Training and evaluating sample 394/800...\n",
      "  Training and evaluating sample 395/800...\n",
      "  Training and evaluating sample 396/800...\n",
      "  Training and evaluating sample 397/800...\n",
      "  Training and evaluating sample 398/800...\n",
      "  Training and evaluating sample 399/800...\n",
      "  Training and evaluating sample 400/800...\n",
      "  Training and evaluating sample 401/800...\n",
      "  Training and evaluating sample 402/800...\n",
      "  Training and evaluating sample 403/800...\n",
      "  Training and evaluating sample 404/800...\n",
      "  Training and evaluating sample 405/800...\n",
      "  Training and evaluating sample 406/800...\n",
      "  Training and evaluating sample 407/800...\n",
      "  Training and evaluating sample 408/800...\n",
      "  Training and evaluating sample 409/800...\n",
      "  Training and evaluating sample 410/800...\n",
      "  Training and evaluating sample 411/800...\n",
      "  Training and evaluating sample 412/800...\n",
      "  Training and evaluating sample 413/800...\n",
      "  Training and evaluating sample 414/800...\n",
      "  Training and evaluating sample 415/800...\n",
      "  Training and evaluating sample 416/800...\n",
      "  Training and evaluating sample 417/800...\n",
      "  Training and evaluating sample 418/800...\n",
      "  Training and evaluating sample 419/800...\n",
      "  Training and evaluating sample 420/800...\n",
      "  Training and evaluating sample 421/800...\n",
      "  Training and evaluating sample 422/800...\n",
      "  Training and evaluating sample 423/800...\n",
      "  Training and evaluating sample 424/800...\n",
      "  Training and evaluating sample 425/800...\n",
      "  Training and evaluating sample 426/800...\n",
      "  Training and evaluating sample 427/800...\n",
      "  Training and evaluating sample 428/800...\n",
      "  Training and evaluating sample 429/800...\n",
      "  Training and evaluating sample 430/800...\n",
      "  Training and evaluating sample 431/800...\n",
      "  Training and evaluating sample 432/800...\n",
      "  Training and evaluating sample 433/800...\n",
      "  Training and evaluating sample 434/800...\n",
      "  Training and evaluating sample 435/800...\n",
      "  Training and evaluating sample 436/800...\n",
      "  Training and evaluating sample 437/800...\n",
      "  Training and evaluating sample 438/800...\n",
      "  Training and evaluating sample 439/800...\n",
      "  Training and evaluating sample 440/800...\n",
      "  Training and evaluating sample 441/800...\n",
      "  Training and evaluating sample 442/800...\n",
      "  Training and evaluating sample 443/800...\n",
      "  Training and evaluating sample 444/800...\n",
      "  Training and evaluating sample 445/800...\n",
      "  Training and evaluating sample 446/800...\n",
      "  Training and evaluating sample 447/800...\n",
      "  Training and evaluating sample 448/800...\n",
      "  Training and evaluating sample 449/800...\n",
      "  Training and evaluating sample 450/800...\n",
      "  Training and evaluating sample 451/800...\n",
      "  Training and evaluating sample 452/800...\n",
      "  Training and evaluating sample 453/800...\n",
      "  Training and evaluating sample 454/800...\n",
      "  Training and evaluating sample 455/800...\n",
      "  Training and evaluating sample 456/800...\n",
      "  Training and evaluating sample 457/800...\n",
      "  Training and evaluating sample 458/800...\n",
      "  Training and evaluating sample 459/800...\n",
      "  Training and evaluating sample 460/800...\n",
      "  Training and evaluating sample 461/800...\n",
      "  Training and evaluating sample 462/800...\n",
      "  Training and evaluating sample 463/800...\n",
      "  Training and evaluating sample 464/800...\n",
      "  Training and evaluating sample 465/800...\n",
      "  Training and evaluating sample 466/800...\n",
      "  Training and evaluating sample 467/800...\n",
      "  Training and evaluating sample 468/800...\n",
      "  Training and evaluating sample 469/800...\n",
      "  Training and evaluating sample 470/800...\n",
      "  Training and evaluating sample 471/800...\n",
      "  Training and evaluating sample 472/800...\n",
      "  Training and evaluating sample 473/800...\n",
      "  Training and evaluating sample 474/800...\n",
      "  Training and evaluating sample 475/800...\n",
      "  Training and evaluating sample 476/800...\n",
      "  Training and evaluating sample 477/800...\n",
      "  Training and evaluating sample 478/800...\n",
      "  Training and evaluating sample 479/800...\n",
      "  Training and evaluating sample 480/800...\n",
      "  Training and evaluating sample 481/800...\n",
      "  Training and evaluating sample 482/800...\n",
      "  Training and evaluating sample 483/800...\n",
      "  Training and evaluating sample 484/800...\n",
      "  Training and evaluating sample 485/800...\n",
      "  Training and evaluating sample 486/800...\n",
      "  Training and evaluating sample 487/800...\n",
      "  Training and evaluating sample 488/800...\n",
      "  Training and evaluating sample 489/800...\n",
      "  Training and evaluating sample 490/800...\n",
      "  Training and evaluating sample 491/800...\n",
      "  Training and evaluating sample 492/800...\n",
      "  Training and evaluating sample 493/800...\n",
      "  Training and evaluating sample 494/800...\n",
      "  Training and evaluating sample 495/800...\n",
      "  Training and evaluating sample 496/800...\n",
      "  Training and evaluating sample 497/800...\n",
      "  Training and evaluating sample 498/800...\n",
      "  Training and evaluating sample 499/800...\n",
      "  Training and evaluating sample 500/800...\n",
      "  Training and evaluating sample 501/800...\n",
      "  Training and evaluating sample 502/800...\n",
      "  Training and evaluating sample 503/800...\n",
      "  Training and evaluating sample 504/800...\n",
      "  Training and evaluating sample 505/800...\n",
      "  Training and evaluating sample 506/800...\n",
      "  Training and evaluating sample 507/800...\n",
      "  Training and evaluating sample 508/800...\n",
      "  Training and evaluating sample 509/800...\n",
      "  Training and evaluating sample 510/800...\n",
      "  Training and evaluating sample 511/800...\n",
      "  Training and evaluating sample 512/800...\n",
      "  Training and evaluating sample 513/800...\n",
      "  Training and evaluating sample 514/800...\n",
      "  Training and evaluating sample 515/800...\n",
      "  Training and evaluating sample 516/800...\n",
      "  Training and evaluating sample 517/800...\n",
      "  Training and evaluating sample 518/800...\n",
      "  Training and evaluating sample 519/800...\n",
      "  Training and evaluating sample 520/800...\n",
      "  Training and evaluating sample 521/800...\n",
      "  Training and evaluating sample 522/800...\n",
      "  Training and evaluating sample 523/800...\n",
      "  Training and evaluating sample 524/800...\n",
      "  Training and evaluating sample 525/800...\n",
      "  Training and evaluating sample 526/800...\n",
      "  Training and evaluating sample 527/800...\n",
      "  Training and evaluating sample 528/800...\n",
      "  Training and evaluating sample 529/800...\n",
      "  Training and evaluating sample 530/800...\n",
      "  Training and evaluating sample 531/800...\n",
      "  Training and evaluating sample 532/800...\n",
      "  Training and evaluating sample 533/800...\n",
      "  Training and evaluating sample 534/800...\n",
      "  Training and evaluating sample 535/800...\n",
      "  Training and evaluating sample 536/800...\n",
      "  Training and evaluating sample 537/800...\n",
      "  Training and evaluating sample 538/800...\n",
      "  Training and evaluating sample 539/800...\n",
      "  Training and evaluating sample 540/800...\n",
      "  Training and evaluating sample 541/800...\n",
      "  Training and evaluating sample 542/800...\n",
      "  Training and evaluating sample 543/800...\n",
      "  Training and evaluating sample 544/800...\n",
      "  Training and evaluating sample 545/800...\n",
      "  Training and evaluating sample 546/800...\n",
      "  Training and evaluating sample 547/800...\n",
      "  Training and evaluating sample 548/800...\n",
      "  Training and evaluating sample 549/800...\n",
      "  Training and evaluating sample 550/800...\n",
      "  Training and evaluating sample 551/800...\n",
      "  Training and evaluating sample 552/800...\n",
      "  Training and evaluating sample 553/800...\n",
      "  Training and evaluating sample 554/800...\n",
      "  Training and evaluating sample 555/800...\n",
      "  Training and evaluating sample 556/800...\n",
      "  Training and evaluating sample 557/800...\n",
      "  Training and evaluating sample 558/800...\n",
      "  Training and evaluating sample 559/800...\n",
      "  Training and evaluating sample 560/800...\n",
      "  Training and evaluating sample 561/800...\n",
      "  Training and evaluating sample 562/800...\n",
      "  Training and evaluating sample 563/800...\n",
      "  Training and evaluating sample 564/800...\n",
      "  Training and evaluating sample 565/800...\n",
      "  Training and evaluating sample 566/800...\n",
      "  Training and evaluating sample 567/800...\n",
      "  Training and evaluating sample 568/800...\n",
      "  Training and evaluating sample 569/800...\n",
      "  Training and evaluating sample 570/800...\n",
      "  Training and evaluating sample 571/800...\n",
      "  Training and evaluating sample 572/800...\n",
      "  Training and evaluating sample 573/800...\n",
      "  Training and evaluating sample 574/800...\n",
      "  Training and evaluating sample 575/800...\n",
      "  Training and evaluating sample 576/800...\n",
      "  Training and evaluating sample 577/800...\n",
      "  Training and evaluating sample 578/800...\n",
      "  Training and evaluating sample 579/800...\n",
      "  Training and evaluating sample 580/800...\n",
      "  Training and evaluating sample 581/800...\n",
      "  Training and evaluating sample 582/800...\n",
      "  Training and evaluating sample 583/800...\n",
      "  Training and evaluating sample 584/800...\n",
      "  Training and evaluating sample 585/800...\n",
      "  Training and evaluating sample 586/800...\n",
      "  Training and evaluating sample 587/800...\n",
      "  Training and evaluating sample 588/800...\n",
      "  Training and evaluating sample 589/800...\n",
      "  Training and evaluating sample 590/800...\n",
      "  Training and evaluating sample 591/800...\n",
      "  Training and evaluating sample 592/800...\n",
      "  Training and evaluating sample 593/800...\n",
      "  Training and evaluating sample 594/800...\n",
      "  Training and evaluating sample 595/800...\n",
      "  Training and evaluating sample 596/800...\n",
      "  Training and evaluating sample 597/800...\n",
      "  Training and evaluating sample 598/800...\n",
      "  Training and evaluating sample 599/800...\n",
      "  Training and evaluating sample 600/800...\n",
      "  Training and evaluating sample 601/800...\n",
      "  Training and evaluating sample 602/800...\n",
      "  Training and evaluating sample 603/800...\n",
      "  Training and evaluating sample 604/800...\n",
      "  Training and evaluating sample 605/800...\n",
      "  Training and evaluating sample 606/800...\n",
      "  Training and evaluating sample 607/800...\n",
      "  Training and evaluating sample 608/800...\n",
      "  Training and evaluating sample 609/800...\n",
      "  Training and evaluating sample 610/800...\n",
      "  Training and evaluating sample 611/800...\n",
      "  Training and evaluating sample 612/800...\n",
      "  Training and evaluating sample 613/800...\n",
      "  Training and evaluating sample 614/800...\n",
      "  Training and evaluating sample 615/800...\n",
      "  Training and evaluating sample 616/800...\n",
      "  Training and evaluating sample 617/800...\n",
      "  Training and evaluating sample 618/800...\n",
      "  Training and evaluating sample 619/800...\n",
      "  Training and evaluating sample 620/800...\n",
      "  Training and evaluating sample 621/800...\n",
      "  Training and evaluating sample 622/800...\n",
      "  Training and evaluating sample 623/800...\n",
      "  Training and evaluating sample 624/800...\n",
      "  Training and evaluating sample 625/800...\n",
      "  Training and evaluating sample 626/800...\n",
      "  Training and evaluating sample 627/800...\n",
      "  Training and evaluating sample 628/800...\n",
      "  Training and evaluating sample 629/800...\n",
      "  Training and evaluating sample 630/800...\n",
      "  Training and evaluating sample 631/800...\n",
      "  Training and evaluating sample 632/800...\n",
      "  Training and evaluating sample 633/800...\n",
      "  Training and evaluating sample 634/800...\n",
      "  Training and evaluating sample 635/800...\n",
      "  Training and evaluating sample 636/800...\n",
      "  Training and evaluating sample 637/800...\n",
      "  Training and evaluating sample 638/800...\n",
      "  Training and evaluating sample 639/800...\n",
      "  Training and evaluating sample 640/800...\n",
      "  Training and evaluating sample 641/800...\n",
      "  Training and evaluating sample 642/800...\n",
      "  Training and evaluating sample 643/800...\n",
      "  Training and evaluating sample 644/800...\n",
      "  Training and evaluating sample 645/800...\n",
      "  Training and evaluating sample 646/800...\n",
      "  Training and evaluating sample 647/800...\n",
      "  Training and evaluating sample 648/800...\n",
      "  Training and evaluating sample 649/800...\n",
      "  Training and evaluating sample 650/800...\n",
      "  Training and evaluating sample 651/800...\n",
      "  Training and evaluating sample 652/800...\n",
      "  Training and evaluating sample 653/800...\n",
      "  Training and evaluating sample 654/800...\n",
      "  Training and evaluating sample 655/800...\n",
      "  Training and evaluating sample 656/800...\n",
      "  Training and evaluating sample 657/800...\n",
      "  Training and evaluating sample 658/800...\n",
      "  Training and evaluating sample 659/800...\n",
      "  Training and evaluating sample 660/800...\n",
      "  Training and evaluating sample 661/800...\n",
      "  Training and evaluating sample 662/800...\n",
      "  Training and evaluating sample 663/800...\n",
      "  Training and evaluating sample 664/800...\n",
      "  Training and evaluating sample 665/800...\n",
      "  Training and evaluating sample 666/800...\n",
      "  Training and evaluating sample 667/800...\n",
      "  Training and evaluating sample 668/800...\n",
      "  Training and evaluating sample 669/800...\n",
      "  Training and evaluating sample 670/800...\n",
      "  Training and evaluating sample 671/800...\n",
      "  Training and evaluating sample 672/800...\n",
      "  Training and evaluating sample 673/800...\n",
      "  Training and evaluating sample 674/800...\n",
      "  Training and evaluating sample 675/800...\n",
      "  Training and evaluating sample 676/800...\n",
      "  Training and evaluating sample 677/800...\n",
      "  Training and evaluating sample 678/800...\n",
      "  Training and evaluating sample 679/800...\n",
      "  Training and evaluating sample 680/800...\n",
      "  Training and evaluating sample 681/800...\n",
      "  Training and evaluating sample 682/800...\n",
      "  Training and evaluating sample 683/800...\n",
      "  Training and evaluating sample 684/800...\n",
      "  Training and evaluating sample 685/800...\n",
      "  Training and evaluating sample 686/800...\n",
      "  Training and evaluating sample 687/800...\n",
      "  Training and evaluating sample 688/800...\n",
      "  Training and evaluating sample 689/800...\n",
      "  Training and evaluating sample 690/800...\n",
      "  Training and evaluating sample 691/800...\n",
      "  Training and evaluating sample 692/800...\n",
      "  Training and evaluating sample 693/800...\n",
      "  Training and evaluating sample 694/800...\n",
      "  Training and evaluating sample 695/800...\n",
      "  Training and evaluating sample 696/800...\n",
      "  Training and evaluating sample 697/800...\n",
      "  Training and evaluating sample 698/800...\n",
      "  Training and evaluating sample 699/800...\n",
      "  Training and evaluating sample 700/800...\n",
      "  Training and evaluating sample 701/800...\n",
      "  Training and evaluating sample 702/800...\n",
      "  Training and evaluating sample 703/800...\n",
      "  Training and evaluating sample 704/800...\n",
      "  Training and evaluating sample 705/800...\n",
      "  Training and evaluating sample 706/800...\n",
      "  Training and evaluating sample 707/800...\n",
      "  Training and evaluating sample 708/800...\n",
      "  Training and evaluating sample 709/800...\n",
      "  Training and evaluating sample 710/800...\n",
      "  Training and evaluating sample 711/800...\n",
      "  Training and evaluating sample 712/800...\n",
      "  Training and evaluating sample 713/800...\n",
      "  Training and evaluating sample 714/800...\n",
      "  Training and evaluating sample 715/800...\n",
      "  Training and evaluating sample 716/800...\n",
      "  Training and evaluating sample 717/800...\n",
      "  Training and evaluating sample 718/800...\n",
      "  Training and evaluating sample 719/800...\n",
      "  Training and evaluating sample 720/800...\n",
      "  Training and evaluating sample 721/800...\n",
      "  Training and evaluating sample 722/800...\n",
      "  Training and evaluating sample 723/800...\n",
      "  Training and evaluating sample 724/800...\n",
      "  Training and evaluating sample 725/800...\n",
      "  Training and evaluating sample 726/800...\n",
      "  Training and evaluating sample 727/800...\n",
      "  Training and evaluating sample 728/800...\n",
      "  Training and evaluating sample 729/800...\n",
      "  Training and evaluating sample 730/800...\n",
      "  Training and evaluating sample 731/800...\n",
      "  Training and evaluating sample 732/800...\n",
      "  Training and evaluating sample 733/800...\n",
      "  Training and evaluating sample 734/800...\n",
      "  Training and evaluating sample 735/800...\n",
      "  Training and evaluating sample 736/800...\n",
      "  Training and evaluating sample 737/800...\n",
      "  Training and evaluating sample 738/800...\n",
      "  Training and evaluating sample 739/800...\n",
      "  Training and evaluating sample 740/800...\n",
      "  Training and evaluating sample 741/800...\n",
      "  Training and evaluating sample 742/800...\n",
      "  Training and evaluating sample 743/800...\n",
      "  Training and evaluating sample 744/800...\n",
      "  Training and evaluating sample 745/800...\n",
      "  Training and evaluating sample 746/800...\n",
      "  Training and evaluating sample 747/800...\n",
      "  Training and evaluating sample 748/800...\n",
      "  Training and evaluating sample 749/800...\n",
      "  Training and evaluating sample 750/800...\n",
      "  Training and evaluating sample 751/800...\n",
      "  Training and evaluating sample 752/800...\n",
      "  Training and evaluating sample 753/800...\n",
      "  Training and evaluating sample 754/800...\n",
      "  Training and evaluating sample 755/800...\n",
      "  Training and evaluating sample 756/800...\n",
      "  Training and evaluating sample 757/800...\n",
      "  Training and evaluating sample 758/800...\n",
      "  Training and evaluating sample 759/800...\n",
      "  Training and evaluating sample 760/800...\n",
      "  Training and evaluating sample 761/800...\n",
      "  Training and evaluating sample 762/800...\n",
      "  Training and evaluating sample 763/800...\n",
      "  Training and evaluating sample 764/800...\n",
      "  Training and evaluating sample 765/800...\n",
      "  Training and evaluating sample 766/800...\n",
      "  Training and evaluating sample 767/800...\n",
      "  Training and evaluating sample 768/800...\n",
      "  Training and evaluating sample 769/800...\n",
      "  Training and evaluating sample 770/800...\n",
      "  Training and evaluating sample 771/800...\n",
      "  Training and evaluating sample 772/800...\n",
      "  Training and evaluating sample 773/800...\n",
      "  Training and evaluating sample 774/800...\n",
      "  Training and evaluating sample 775/800...\n",
      "  Training and evaluating sample 776/800...\n",
      "  Training and evaluating sample 777/800...\n",
      "  Training and evaluating sample 778/800...\n",
      "  Training and evaluating sample 779/800...\n",
      "  Training and evaluating sample 780/800...\n",
      "  Training and evaluating sample 781/800...\n",
      "  Training and evaluating sample 782/800...\n",
      "  Training and evaluating sample 783/800...\n",
      "  Training and evaluating sample 784/800...\n",
      "  Training and evaluating sample 785/800...\n",
      "  Training and evaluating sample 786/800...\n",
      "  Training and evaluating sample 787/800...\n",
      "  Training and evaluating sample 788/800...\n",
      "  Training and evaluating sample 789/800...\n",
      "  Training and evaluating sample 790/800...\n",
      "  Training and evaluating sample 791/800...\n",
      "  Training and evaluating sample 792/800...\n",
      "  Training and evaluating sample 793/800...\n",
      "  Training and evaluating sample 794/800...\n",
      "  Training and evaluating sample 795/800...\n",
      "  Training and evaluating sample 796/800...\n",
      "  Training and evaluating sample 797/800...\n",
      "  Training and evaluating sample 798/800...\n",
      "  Training and evaluating sample 799/800...\n",
      "  Training and evaluating sample 800/800...\n",
      "  Average CV score: 0.8850\n",
      "Evaluating parameter set 2/80: {'tol': np.float64(1e-06), 'max_iter': 4000, 'kernel': 'linear', 'class_weight': 'balanced', 'C': np.float64(100.0)}\n",
      "  Training and evaluating sample 1/800...\n",
      "  Training and evaluating sample 2/800...\n",
      "  Training and evaluating sample 3/800...\n",
      "  Training and evaluating sample 4/800...\n",
      "  Training and evaluating sample 5/800...\n",
      "  Training and evaluating sample 6/800...\n",
      "  Training and evaluating sample 7/800...\n",
      "  Training and evaluating sample 8/800...\n",
      "  Training and evaluating sample 9/800...\n",
      "  Training and evaluating sample 10/800...\n",
      "  Training and evaluating sample 11/800...\n",
      "  Training and evaluating sample 12/800...\n",
      "  Training and evaluating sample 13/800...\n",
      "  Training and evaluating sample 14/800...\n",
      "  Training and evaluating sample 15/800...\n",
      "  Training and evaluating sample 16/800...\n",
      "  Training and evaluating sample 17/800...\n",
      "  Training and evaluating sample 18/800...\n",
      "  Training and evaluating sample 19/800...\n",
      "  Training and evaluating sample 20/800...\n",
      "  Training and evaluating sample 21/800...\n",
      "  Training and evaluating sample 22/800...\n",
      "  Training and evaluating sample 23/800...\n",
      "  Training and evaluating sample 24/800...\n",
      "  Training and evaluating sample 25/800...\n",
      "  Training and evaluating sample 26/800...\n",
      "  Training and evaluating sample 27/800...\n",
      "  Training and evaluating sample 28/800...\n",
      "  Training and evaluating sample 29/800...\n",
      "  Training and evaluating sample 30/800...\n",
      "  Training and evaluating sample 31/800...\n",
      "  Training and evaluating sample 32/800...\n",
      "  Training and evaluating sample 33/800...\n",
      "  Training and evaluating sample 34/800...\n",
      "  Training and evaluating sample 35/800...\n",
      "  Training and evaluating sample 36/800...\n",
      "  Training and evaluating sample 37/800...\n",
      "  Training and evaluating sample 38/800...\n",
      "  Training and evaluating sample 39/800...\n",
      "  Training and evaluating sample 40/800...\n",
      "  Training and evaluating sample 41/800...\n",
      "  Training and evaluating sample 42/800...\n",
      "  Training and evaluating sample 43/800...\n",
      "  Training and evaluating sample 44/800...\n",
      "  Training and evaluating sample 45/800...\n",
      "  Training and evaluating sample 46/800...\n",
      "  Training and evaluating sample 47/800...\n",
      "  Training and evaluating sample 48/800...\n",
      "  Training and evaluating sample 49/800...\n",
      "  Training and evaluating sample 50/800...\n",
      "  Training and evaluating sample 51/800...\n",
      "  Training and evaluating sample 52/800...\n",
      "  Training and evaluating sample 53/800...\n",
      "  Training and evaluating sample 54/800...\n",
      "  Training and evaluating sample 55/800...\n",
      "  Training and evaluating sample 56/800...\n",
      "  Training and evaluating sample 57/800...\n",
      "  Training and evaluating sample 58/800...\n",
      "  Training and evaluating sample 59/800...\n",
      "  Training and evaluating sample 60/800...\n",
      "  Training and evaluating sample 61/800...\n",
      "  Training and evaluating sample 62/800...\n",
      "  Training and evaluating sample 63/800...\n",
      "  Training and evaluating sample 64/800...\n",
      "  Training and evaluating sample 65/800...\n",
      "  Training and evaluating sample 66/800...\n",
      "  Training and evaluating sample 67/800...\n",
      "  Training and evaluating sample 68/800...\n",
      "  Training and evaluating sample 69/800...\n",
      "  Training and evaluating sample 70/800...\n",
      "  Training and evaluating sample 71/800...\n",
      "  Training and evaluating sample 72/800...\n",
      "  Training and evaluating sample 73/800...\n",
      "  Training and evaluating sample 74/800...\n",
      "  Training and evaluating sample 75/800...\n",
      "  Training and evaluating sample 76/800...\n",
      "  Training and evaluating sample 77/800...\n",
      "  Training and evaluating sample 78/800...\n",
      "  Training and evaluating sample 79/800...\n",
      "  Training and evaluating sample 80/800...\n",
      "  Training and evaluating sample 81/800...\n",
      "  Training and evaluating sample 82/800...\n",
      "  Training and evaluating sample 83/800...\n",
      "  Training and evaluating sample 84/800...\n",
      "  Training and evaluating sample 85/800...\n",
      "  Training and evaluating sample 86/800...\n",
      "  Training and evaluating sample 87/800...\n",
      "  Training and evaluating sample 88/800...\n",
      "  Training and evaluating sample 89/800...\n",
      "  Training and evaluating sample 90/800...\n",
      "  Training and evaluating sample 91/800...\n",
      "  Training and evaluating sample 92/800...\n",
      "  Training and evaluating sample 93/800...\n",
      "  Training and evaluating sample 94/800...\n",
      "  Training and evaluating sample 95/800...\n",
      "  Training and evaluating sample 96/800...\n",
      "  Training and evaluating sample 97/800...\n",
      "  Training and evaluating sample 98/800...\n",
      "  Training and evaluating sample 99/800...\n",
      "  Training and evaluating sample 100/800...\n",
      "  Training and evaluating sample 101/800...\n",
      "  Training and evaluating sample 102/800...\n",
      "  Training and evaluating sample 103/800...\n",
      "  Training and evaluating sample 104/800...\n",
      "  Training and evaluating sample 105/800...\n",
      "  Training and evaluating sample 106/800...\n",
      "  Training and evaluating sample 107/800...\n",
      "  Training and evaluating sample 108/800...\n",
      "  Training and evaluating sample 109/800...\n",
      "  Training and evaluating sample 110/800...\n",
      "  Training and evaluating sample 111/800...\n",
      "  Training and evaluating sample 112/800...\n",
      "  Training and evaluating sample 113/800...\n",
      "  Training and evaluating sample 114/800...\n",
      "  Training and evaluating sample 115/800...\n",
      "  Training and evaluating sample 116/800...\n",
      "  Training and evaluating sample 117/800...\n",
      "  Training and evaluating sample 118/800...\n",
      "  Training and evaluating sample 119/800...\n",
      "  Training and evaluating sample 120/800...\n",
      "  Training and evaluating sample 121/800...\n",
      "  Training and evaluating sample 122/800...\n",
      "  Training and evaluating sample 123/800...\n",
      "  Training and evaluating sample 124/800...\n",
      "  Training and evaluating sample 125/800...\n",
      "  Training and evaluating sample 126/800...\n",
      "  Training and evaluating sample 127/800...\n",
      "  Training and evaluating sample 128/800...\n",
      "  Training and evaluating sample 129/800...\n",
      "  Training and evaluating sample 130/800...\n",
      "  Training and evaluating sample 131/800...\n",
      "  Training and evaluating sample 132/800...\n",
      "  Training and evaluating sample 133/800...\n",
      "  Training and evaluating sample 134/800...\n",
      "  Training and evaluating sample 135/800...\n",
      "  Training and evaluating sample 136/800...\n",
      "  Training and evaluating sample 137/800...\n",
      "  Training and evaluating sample 138/800...\n",
      "  Training and evaluating sample 139/800...\n",
      "  Training and evaluating sample 140/800...\n",
      "  Training and evaluating sample 141/800...\n",
      "  Training and evaluating sample 142/800...\n",
      "  Training and evaluating sample 143/800...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The work in this thread was cancelled.\nObtained 33 stack frames\n#1 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/pylibraft/common/handle.cpython-312-x86_64-linux-gnu.so(+0x3a82b) [0x7f6136a9182b]\n#2 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/pylibraft/common/handle.cpython-312-x86_64-linux-gnu.so(+0x41700) [0x7f6136a98700]\n#3 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cuml/svm/svc.cpython-312-x86_64-linux-gnu.so(+0x4707e) [0x7f60eafa307e]\n#4 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#5 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyEval_EvalCode +0xa1 [0x5639a83de741]\n#6 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d5ece) [0x5639a83f9ece]\n#7 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x112f8e) [0x5639a8236f8e]\n#8 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d099f) [0x5639a83f499f]\n#9 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d1c57) [0x5639a83f5c57]\n#10 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113e38) [0x5639a8237e38]\n#11 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x251adc) [0x5639a8375adc]\n#12 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2515be) [0x5639a83755be]\n#13 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: _PyObject_Call +0x12b [0x5639a83591ab]\n#14 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#15 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d099f) [0x5639a83f499f]\n#16 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x8274) [0x7f6344cf3274]\n#17 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x8a63) [0x7f6344cf3a63]\n#18 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x222fbc) [0x5639a8346fbc]\n#19 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x34db0c) [0x5639a8471b0c]\n#20 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x1c402e) [0x5639a82e802e]\n#21 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x21940b) [0x5639a833d40b]\n#22 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#23 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyEval_EvalCode +0xa1 [0x5639a83de741]\n#24 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d5ece) [0x5639a83f9ece]\n#25 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x21940b) [0x5639a833d40b]\n#26 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyObject_Vectorcall +0x2e [0x5639a833d1ae]\n#27 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x1126a1) [0x5639a82366a1]\n#28 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2eb328) [0x5639a840f328]\n#29 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: Py_RunMain +0x3d1 [0x5639a840eed1]\n#30 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: Py_BytesMain +0x37 [0x5639a83c90c7]\n#31 in /lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f63461af1ca]\n#32 in /lib/x86_64-linux-gnu/libc.so.6: __libc_start_main +0x8b [0x7f63461af28b]\n#33 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2a4f71) [0x5639a83c8f71]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m searcher \u001b[38;5;241m=\u001b[39m CuMLRandomizedSearchCV(param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloocv\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m, in \u001b[0;36mCuMLRandomizedSearchCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sampled_params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_parameters()):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating parameter set \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampled_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m     avg_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Average CV score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: sampled_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_score})\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mCuMLRandomizedSearchCV._train_and_evaluate\u001b[0;34m(self, X, y, sampled_params)\u001b[0m\n\u001b[1;32m     29\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stratified_kfold_cv(X, y, sampled_params)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloocv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loocv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid cv_method. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkfold\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstratified\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloocv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 83\u001b[0m, in \u001b[0;36mCuMLRandomizedSearchCV._loocv\u001b[0;34m(self, X, y, sampled_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m     82\u001b[0m CuMLRandomizedSearchCV\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampled_params)\n\u001b[0;32m---> 83\u001b[0m \u001b[43mCuMLRandomizedSearchCV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m score \u001b[38;5;241m=\u001b[39m CuMLRandomizedSearchCV\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mscore(X_val, y_val)\n\u001b[1;32m     85\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cuml/internals/api_decorators.py:188\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     set_api_output_dtype(output_dtype)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_return:\n\u001b[0;32m--> 188\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32msvc.pyx:589\u001b[0m, in \u001b[0;36mcuml.svm.svc.SVC.fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhandle.pyx:120\u001b[0m, in \u001b[0;36mpylibraft.common.handle.DeviceResources.sync\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The work in this thread was cancelled.\nObtained 33 stack frames\n#1 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/pylibraft/common/handle.cpython-312-x86_64-linux-gnu.so(+0x3a82b) [0x7f6136a9182b]\n#2 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/pylibraft/common/handle.cpython-312-x86_64-linux-gnu.so(+0x41700) [0x7f6136a98700]\n#3 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cuml/svm/svc.cpython-312-x86_64-linux-gnu.so(+0x4707e) [0x7f60eafa307e]\n#4 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#5 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyEval_EvalCode +0xa1 [0x5639a83de741]\n#6 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d5ece) [0x5639a83f9ece]\n#7 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x112f8e) [0x5639a8236f8e]\n#8 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d099f) [0x5639a83f499f]\n#9 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d1c57) [0x5639a83f5c57]\n#10 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113e38) [0x5639a8237e38]\n#11 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x251adc) [0x5639a8375adc]\n#12 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2515be) [0x5639a83755be]\n#13 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: _PyObject_Call +0x12b [0x5639a83591ab]\n#14 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#15 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d099f) [0x5639a83f499f]\n#16 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x8274) [0x7f6344cf3274]\n#17 in /home/chris/miniconda3/envs/rapids-24.12/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x8a63) [0x7f6344cf3a63]\n#18 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x222fbc) [0x5639a8346fbc]\n#19 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x34db0c) [0x5639a8471b0c]\n#20 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x1c402e) [0x5639a82e802e]\n#21 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x21940b) [0x5639a833d40b]\n#22 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x113339) [0x5639a8237339]\n#23 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyEval_EvalCode +0xa1 [0x5639a83de741]\n#24 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2d5ece) [0x5639a83f9ece]\n#25 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x21940b) [0x5639a833d40b]\n#26 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: PyObject_Vectorcall +0x2e [0x5639a833d1ae]\n#27 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x1126a1) [0x5639a82366a1]\n#28 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2eb328) [0x5639a840f328]\n#29 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: Py_RunMain +0x3d1 [0x5639a840eed1]\n#30 in /home/chris/miniconda3/envs/rapids-24.12/bin/python: Py_BytesMain +0x37 [0x5639a83c90c7]\n#31 in /lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f63461af1ca]\n#32 in /lib/x86_64-linux-gnu/libc.so.6: __libc_start_main +0x8b [0x7f63461af28b]\n#33 in /home/chris/miniconda3/envs/rapids-24.12/bin/python(+0x2a4f71) [0x5639a83c8f71]\n"
     ]
    }
   ],
   "source": [
    "searcher = CuMLRandomizedSearchCV(param_distributions=param_distributions, n_iter=20, cv_method='loocv', k=5, random_state=60)\n",
    "searcher.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0368af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RANDOMIZED SEARCH CV RESULTS\n",
      "==================================================\n",
      "\n",
      "Best Parameters Found:\n",
      "  tol: 1e-07\n",
      "  max_iter: 5000\n",
      "  kernel: linear\n",
      "  class_weight: balanced\n",
      "  C: 1.0\n",
      "\n",
      "Model Performance:\n",
      "  Validation Accuracy: 83.00%\n",
      "  Test Accuracy: 74.03%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "best_model = SVC(**searcher.get_best_params())\n",
    "best_model.fit(train_set, train_labels)\n",
    "test_predictions = best_model.predict(test_set)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOMIZED SEARCH CV RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param, value in searcher.get_best_params().items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "print(f\"  Validation Accuracy: {searcher.get_best_score()*100:.2f}%\")\n",
    "print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2f34f",
   "metadata": {},
   "source": [
    "# Further Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb8531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridCV = {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.01, 0.1, 0.8, 0.9, 1, 1.1, 1.2, 2, 5, 10], \n",
    "        'tol': [0.01, 0.01, 0.1],\n",
    "        'gamma': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'degree': [4, 5, 6],\n",
    "        'max_iter': np.linspace(3900, 4100, 10),\n",
    "        'class_weight': ['balanced'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12107029",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m svc_tuned \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[1;32m      3\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(svc_tuned, param_gridCV, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:932\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    928\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 932\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    935\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2716\u001b[0m, in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2711\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cv\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cv, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m   2713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2714\u001b[0m         classifier\n\u001b[1;32m   2715\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2716\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   2717\u001b[0m     ):\n\u001b[1;32m   2718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m StratifiedKFold(cv)\n\u001b[1;32m   2719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:333\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:172\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/sklearn/utils/_array_api.py:832\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    830\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 832\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/utils/performance_tracking.py:51\u001b[0m, in \u001b[0;36m_performance_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nvtx\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m     44\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m     45\u001b[0m         nvtx\u001b[38;5;241m.\u001b[39mannotate(\n\u001b[1;32m     46\u001b[0m             message\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24.12/lib/python3.12/site-packages/cudf/core/frame.py:440\u001b[0m, in \u001b[0;36mFrame.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;129m@_performance_tracking\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplicit conversion to a host NumPy array via __array__ is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed, To explicitly construct a GPU matrix, consider using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.to_cupy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo explicitly construct a host matrix, consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing .to_numpy().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a host NumPy array via __array__ is not allowed, To explicitly construct a GPU matrix, consider using .to_cupy()\nTo explicitly construct a host matrix, consider using .to_numpy()."
     ]
    }
   ],
   "source": [
    "from cuml.model_selection import GridSearchCV\n",
    "svc_tuned = SVC()\n",
    "grid_search = GridSearchCV(svc_tuned, param_gridCV, cv=5)\n",
    "grid_search.fit(train_set, train_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
